{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc50c5a-0348-4d48-a779-fd586ee49a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '/mnt/DataRAID/melismail/PDAC'\n",
    "import os\n",
    "os.chdir(working_directory)\n",
    "from pickle_utils import write_pickle, read_pickle\n",
    "\n",
    "import sys, cv2, math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "from numpy import argmax\n",
    "from tifffile import imread, imsave\n",
    "from glob import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from scikitplot.metrics import plot_roc, plot_precision_recall, plot_confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "np.random.seed(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3555ff-855e-474c-b544-50622b67b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/mnt/DataRAID/melismail/PDAC/data'\n",
    "preprocessing_path ='Preprocessing_mask_annotation'\n",
    "model_path = 'InceptionV3' #ResNet50 #VGG-16\n",
    "clustering_path = 'Clustering'\n",
    "plot_path = 'plots/Clustering' \n",
    "class_path = 'two_classes/masks' #celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d630757-66e4-47a0-8ae6-830a1751d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = read_pickle(path=os.path.join(base_path, preprocessing_path, model_path, f\"{model_path}_celltypes_lbl_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c38a6e-67e9-41bb-972d-5d94e93a7889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pseudonym  tile_id    lbl_mask  Acinar cells  Alpha cells  B cells  Basal  \\\n",
      "0  IAA2LDX17  (0, 10)  non-cancer           0.0          0.0      0.0    0.0   \n",
      "1  IAA2LDX17  (0, 11)  non-cancer           0.0          0.0      0.0    0.0   \n",
      "2  IAA2LDX17  (0, 12)  non-cancer           1.0          0.0      4.0    6.0   \n",
      "3  IAA2LDX17  (0, 13)  non-cancer           0.0          0.0      0.0    0.0   \n",
      "4  1C73PUTH4   (1, 2)  non-cancer           0.0          0.0      0.0    1.0   \n",
      "\n",
      "   Beta cells  Classical_CEACAM  Classical_KRT7  ...  NK cells  Schwann cells  \\\n",
      "0         0.0               1.0             2.0  ...       0.0            0.0   \n",
      "1         0.0               3.0             0.0  ...       0.0            0.0   \n",
      "2         1.0              30.0             1.0  ...       2.0            2.0   \n",
      "3         0.0               1.0             0.0  ...       0.0            0.0   \n",
      "4         0.0               0.0             0.0  ...       0.0            0.0   \n",
      "\n",
      "   T cells  iCAF  myCAF_ACTA2  myCAF_POSTN  most_prevalent_cancer  \\\n",
      "0      0.0   0.0          0.0          0.0         Classical_KRT7   \n",
      "1      0.0   0.0          0.0          0.0       Classical_CEACAM   \n",
      "2      1.0   1.0          2.0          0.0       Classical_CEACAM   \n",
      "3      0.0   0.0          0.0          0.0       Classical_CEACAM   \n",
      "4      0.0   0.0          0.0          1.0                  Basal   \n",
      "\n",
      "                                            Features     lbl   same  \n",
      "0  [0.11127892, 0.082550116, 0.013145252, 0.14383...  cancer  False  \n",
      "1  [0.088218965, 0.045640353, 0.0048801894, 0.144...  cancer  False  \n",
      "2  [0.14599374, 0.060965236, 0.00016441147, 0.136...  cancer  False  \n",
      "3  [0.16967882, 0.14898822, 0.01608835, 0.1665820...  cancer  False  \n",
      "4  [0.036901504, 0.026912397, 0.0048136557, 0.123...  cancer  False  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb24cbfd-ff63-412d-b2ab-c0f7d0a31138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset[\"Features\"].to_list()\n",
    "y = df_dataset[\"lbl_masks\"] #lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9fbf69-a8f3-414f-a2aa-63bf1a26627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cancer', 1: 'non-cancer'}\n",
      "['cancer', 'non-cancer']\n"
     ]
    }
   ],
   "source": [
    "y_dic = {idx: i for idx, i in enumerate(np.unique(y))}\n",
    "classes = sorted(y_dic.items(), key=lambda item: item[0])\n",
    "classes = [i[1] for i in classes]\n",
    "print(y_dic)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f174e6-122d-4cce-8515-a0b3e9bfa1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060bb15d-8938-4b04-9eef-c556d5fb654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({1: 7332, 0: 2268})\n",
      "Testing target statistics: Counter({1: 1838, 0: 563})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dec0c0-f43b-464a-a8c3-479373befb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_test(X_tr, X_te, y_tr, y_te, plot_dir:str, model_name:str, threshold=False, scaler:str='', balancer:str=''):\n",
    "    print( model_name, scaler, balancer, threshold)\n",
    "\n",
    "    direct = os.path.join(plot_dir, model_name, scaler, balancer, 'Threshold' if threshold else '') \n",
    "    os.makedirs(direct, exist_ok=True)\n",
    "\n",
    "    #scale data\n",
    "    if scaler == 'StandardScaler':\n",
    "        std_scaler = StandardScaler().fit(X_tr + X_te)\n",
    "        X_tr_scaled = std_scaler.transform(X_tr)\n",
    "        X_te_scaled = std_scaler.transform(X_te)\n",
    "    elif scaler == 'MinMaxScaler':\n",
    "        minmax_scaler = MinMaxScaler().fit(X_tr + X_te)\n",
    "        X_tr_scaled = minmax_scaler.transform(X_tr)\n",
    "        X_te_scaled = minmax_scaler.transform(X_te)\n",
    "    else:\n",
    "        X_tr_scaled = X_tr\n",
    "        X_te_scaled = X_te\n",
    "    \n",
    "    \n",
    "    #balance dataset\n",
    "    if balancer == 'RandomOversampler':\n",
    "        over_sampler = RandomOverSampler(random_state=109)\n",
    "        X_tr_sampled, y_tr_sampled = over_sampler.fit_resample(X_tr_scaled, y_tr)\n",
    "    elif balancer == 'RandomUndersampler':\n",
    "        under_sampler = RandomUnderSampler(random_state=109)\n",
    "        X_tr_sampled, y_tr_sampled = under_sampler.fit_resample(X_tr_scaled, y_tr)\n",
    "    else:\n",
    "        X_tr_sampled, y_tr_sampled = X_tr_scaled, y_tr\n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    if model_name == 'SVM':\n",
    "        model = svm.SVC(kernel=\"linear\", C=1.0, probability=True)\n",
    "        model.fit(X_tr_sampled, y_tr_sampled)\n",
    "        y_pred = model.predict(X_te_scaled)\n",
    "    elif model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression(max_iter=1500)\n",
    "        model.fit(X_tr_sampled, y_tr_sampled)\n",
    "        y_pred = model.predict(X_te_scaled)\n",
    "    else:\n",
    "        print(f'WARNING no {model} model found!')\n",
    "        \n",
    "    #print metrices    \n",
    "    result_dic = {f'Model': model,\n",
    "                  f'Balancer': balancer,\n",
    "                  f'Scaler': scaler,\n",
    "                  f'Precision score': precision_score(y_te, y_pred),\n",
    "                  f'Recall score':  recall_score(y_te, y_pred),\n",
    "                  f'F1-score score': f1_score(y_te, y_pred),\n",
    "                  f'Accuracy score': accuracy_score(y_te, y_pred),\n",
    "                  f'Area under the ROC curve (AUC)': roc_auc_score(y_te, y_pred)}\n",
    "\n",
    "    \n",
    "    y_score = model.predict_proba(X_te)\n",
    "    fpr0, tpr0, thresholds = roc_curve(y_te, y_score[:, 1])\n",
    "    roc_auc0 = auc(fpr0, tpr0)\n",
    "    \n",
    "    # Calculate the best threshold\n",
    "    best_threshold = None\n",
    "    if threshold:\n",
    "        J = tpr0 - fpr0\n",
    "        ix = argmax(J) # take the value which maximizes the J variable\n",
    "        best_threshold = thresholds[ix]\n",
    "        # adjust score according to threshold.\n",
    "        y_score = np.array([[1, y[1]] if y[0] >= best_threshold else [0, y[1]] for y in y_score])\n",
    "        \n",
    "    \n",
    "    result_dic['cm'] = confusion_matrix(y_te, y_pred)\n",
    "    \n",
    "    \n",
    "       \n",
    "    # Plot metrics \n",
    "    plot_roc(y_te, y_score)\n",
    "    plt.title(f'ROC curve of \\n model:{model} scaler:{scaler} \\n balancer:{balancer}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(direct, 'roc.png'))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    plot_precision_recall(y_te, y_score)\n",
    "    plt.title(f'Precision Recall curve of \\n model:{model} scaler:{scaler} \\n balancer:{balancer}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(direct, 'precision_recall.png'))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    plot_confusion_matrix(y_te, y_pred, cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix of \\n model:{model} scaler:{scaler} \\n balancer:{balancer}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(os.path.join(direct, 'Confusion_Matrix.png'))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    # Print a classification report\n",
    "    result_dic['classification_report'] = classification_report(y_te, y_pred)\n",
    "                \n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66848cf4-f53f-43fb-ae5a-05330d131d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MinMaxScaler RandomOversampler True\n",
      "SVM MinMaxScaler RandomOversampler False\n",
      "LogisticRegression MinMaxScaler RandomOversampler True\n",
      "LogisticRegression MinMaxScaler RandomOversampler False\n",
      "SVM MinMaxScaler RandomUndersampler True\n",
      "SVM MinMaxScaler RandomUndersampler False\n",
      "LogisticRegression MinMaxScaler RandomUndersampler True\n",
      "LogisticRegression MinMaxScaler RandomUndersampler False\n",
      "SVM MinMaxScaler  True\n",
      "SVM MinMaxScaler  False\n",
      "LogisticRegression MinMaxScaler  True\n",
      "LogisticRegression MinMaxScaler  False\n",
      "SVM StandardScaler RandomOversampler True\n"
     ]
    }
   ],
   "source": [
    "balancer_list = ['RandomOversampler', 'RandomUndersampler', '']\n",
    "scaler_list = ['MinMaxScaler', 'StandardScaler', '']\n",
    "ml_model_list = ['SVM', 'LogisticRegression']\n",
    "threshold_list = [True, False]\n",
    "\n",
    "classification_dic  = [build_and_test(X_tr=X_train, X_te=X_test, y_tr=y_train, y_te=y_test, plot_dir=os.path.join(base_path, plot_path, class_path, model_path), model_name = m, threshold=t, scaler=s, balancer=b)\n",
    "                       for s in scaler_list\n",
    "                       for b in balancer_list\n",
    "                       for m in ml_model_list\n",
    "                       for t in threshold_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab2924-971f-422c-b704-eb2cf7d49dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = pd.DataFrame(classification_dic)\n",
    "df_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecbc1d-668b-4b47-9987-004791b7b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path= os.path.join(base_path, clustering_path, class_path, model_path, f\"{model_path}_classification_dict.pkl\"), obj=classification_dic)\n",
    "write_pickle(path= os.path.join(base_path, clustering_path, class_path, model_path, f\"{model_path}_classification_df.pkl\"), obj=df_classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDAC",
   "language": "python",
   "name": "pdac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

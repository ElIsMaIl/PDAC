{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc50c5a-0348-4d48-a779-fd586ee49a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '/mnt/DataRAID/melismail/PDAC'\n",
    "import os\n",
    "os.chdir(working_directory)\n",
    "from pickle_utils import write_pickle, read_pickle\n",
    "\n",
    "import sys, math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "from numpy import argmax\n",
    "from tifffile import imread, imsave\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from scikitplot.metrics import plot_roc, plot_precision_recall, plot_confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "np.random.seed(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d3555ff-855e-474c-b544-50622b67b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/mnt/DataRAID/melismail/PDAC/data'\n",
    "preprocessing_path ='Preprocessing_mask_annotation'\n",
    "model_path = 'InceptionV3' #VGG-16 #ResNet50\n",
    "classification_path = 'Classification'\n",
    "plot_path = 'plots/Classification' \n",
    "class_path = 'six_classes/celltypes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d630757-66e4-47a0-8ae6-830a1751d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = read_pickle(path=os.path.join(base_path, preprocessing_path, model_path, f\"{model_path}_celltypes_lbl_df.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c38a6e-67e9-41bb-972d-5d94e93a7889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pseudonym  tile_id    lbl_mask  Acinar cells  Alpha cells  B cells  Basal  \\\n",
      "0  IAA2LDX17  (1, 23)  non-cancer           0.0          0.0      0.0    0.0   \n",
      "1  IAA2LDX17  (1, 27)  non-cancer           0.0          0.0      1.0    2.0   \n",
      "2  IAA2LDX17  (1, 28)  non-cancer           0.0          0.0      1.0    1.0   \n",
      "3  IAA2LDX17  (1, 29)  non-cancer           1.0          0.0      0.0    1.0   \n",
      "4  18QH2FGR4  (2, 17)  non-cancer           0.0          0.0      0.0    0.0   \n",
      "\n",
      "   Beta cells  Classical_CEACAM  Classical_KRT7  ...  NK cells  Schwann cells  \\\n",
      "0         0.0               1.0             2.0  ...       0.0            0.0   \n",
      "1         0.0               8.0             0.0  ...       0.0            0.0   \n",
      "2         1.0              12.0             0.0  ...       2.0            1.0   \n",
      "3         0.0               2.0             0.0  ...       0.0            0.0   \n",
      "4         0.0               0.0             0.0  ...       0.0            0.0   \n",
      "\n",
      "   T cells  iCAF  myCAF_ACTA2  myCAF_POSTN  most_prevalent_cancer  \\\n",
      "0      0.0   0.0          0.0          0.0         Classical_KRT7   \n",
      "1      0.0   0.0          0.0          0.0       Classical_CEACAM   \n",
      "2      0.0   0.0          1.0          0.0       Classical_CEACAM   \n",
      "3      0.0   0.0          1.0          0.0         Classical_TFF1   \n",
      "4      0.0   0.0          0.0          1.0         Classical_TFF1   \n",
      "\n",
      "                                            Features     lbl   same  \n",
      "0  [0.0, 0.019235041, 0.0183595, 0.0, 0.06919923,...  cancer  False  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28502965, 0.0...  cancer  False  \n",
      "2  [0.0, 0.0075863334, 0.0, 0.0, 0.0, 0.0, 0.2246...  cancer  False  \n",
      "3  [0.0, 0.01709919, 0.017997922, 0.0, 0.0, 0.0, ...  cancer  False  \n",
      "4  [0.12779504, 0.008282632, 0.0, 0.024128607, 0....  cancer  False  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb24cbfd-ff63-412d-b2ab-c0f7d0a31138",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset[\"Features\"].to_list()\n",
    "y = df_dataset[\"most_prevalent_cancer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a258285c-c9eb-4777-acad-5622bfd98134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Basal', 1: 'Classical_CEACAM', 2: 'Classical_KRT7', 3: 'Classical_REG4', 4: 'Classical_TFF1', 5: 'non-cancer'}\n",
      "['Basal', 'Classical_CEACAM', 'Classical_KRT7', 'Classical_REG4', 'Classical_TFF1', 'non-cancer']\n"
     ]
    }
   ],
   "source": [
    "y_dic = {idx: i for idx, i in enumerate(np.unique(y))}\n",
    "classes = sorted(y_dic.items(), key=lambda item: item[0])\n",
    "classes = [i[1] for i in classes]\n",
    "print(y_dic)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e342fcd7-455e-497b-a45d-fc4b48c231b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = label_binarize(y, classes=classes)\n",
    "#n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f174e6-122d-4cce-8515-a0b3e9bfa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abab356-6ec5-4cc1-b5fc-fdc9aad78247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 ... 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b30ae2e-91da-4e5e-ada2-ffac7ef57a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-cancer          1849\n",
      "Classical_TFF1       152\n",
      "Classical_CEACAM     135\n",
      "Basal                 98\n",
      "Classical_KRT7        91\n",
      "Classical_REG4         4\n",
      "Name: most_prevalent_cancer, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df_dataset, x=\"most_prevalent_cancer\", order=sorted(df_dataset[\"most_prevalent_cancer\"].unique()), color=\"blue\")\n",
    "plt.xlabel('Multi-class Labels')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{model_path}_six_class_countplot.png', dpi=300)\n",
    "print(df_dataset[\"most_prevalent_cancer\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060bb15d-8938-4b04-9eef-c556d5fb654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)\n",
    "#print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "#print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08dec0c0-f43b-464a-a8c3-479373befb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_test(X_tr, X_te, y_tr, y_te, plot_dir:str, model_name:str, parameter:dict, scaler:str, balancer:str, cv: int):\n",
    "    print(model_name, scaler, balancer, parameter, cv)\n",
    "        \n",
    "    direct = os.path.join(plot_dir, model_name, scaler, balancer) \n",
    "    os.makedirs(direct, exist_ok=True)\n",
    "\n",
    "    model_dir = os.path.join(base_path, classification_path, class_path, model_path, model_name, scaler, balancer)\n",
    "    os.makedirs(direct, exist_ok=True)\n",
    "\n",
    "    target_file = os.path.join(model_dir, f\"Classifier_{cv}.pkl\")\n",
    "    if os.path.isfile(target_file):\n",
    "                               return read_pickle(target_file)\n",
    "\n",
    "    \n",
    "    if balancer == 'RandomOversampler' and model_name == 'LogisticRegression':\n",
    "        reg_dic = {f'Model_Name': model_name,\n",
    "                   f'Balancer': balancer,\n",
    "                   f'Scaler': scaler}\n",
    "        return reg_dic\n",
    "\n",
    "    #scale data\n",
    "    if scaler == 'StandardScaler':\n",
    "        std_scaler = StandardScaler().fit(X_tr + X_te)\n",
    "        X_tr_scaled = std_scaler.transform(X_tr)\n",
    "        X_te_scaled = std_scaler.transform(X_te)\n",
    "    elif scaler == 'MinMaxScaler':\n",
    "        minmax_scaler = MinMaxScaler().fit(X_tr + X_te)\n",
    "        X_tr_scaled = minmax_scaler.transform(X_tr)\n",
    "        X_te_scaled = minmax_scaler.transform(X_te)\n",
    "    else:\n",
    "        X_tr_scaled = X_tr\n",
    "        X_te_scaled = X_te\n",
    "    \n",
    "    \n",
    "    #balance dataset\n",
    "    if balancer == 'RandomOversampler':\n",
    "        over_sampler = RandomOverSampler(random_state=109)\n",
    "        X_tr_sampled, y_tr_sampled = over_sampler.fit_resample(X_tr_scaled, y_tr)\n",
    "    elif balancer == 'RandomUndersampler':\n",
    "        under_sampler = RandomUnderSampler(random_state=109)\n",
    "        X_tr_sampled, y_tr_sampled = under_sampler.fit_resample(X_tr_scaled, y_tr)\n",
    "    else:\n",
    "        X_tr_sampled, y_tr_sampled = X_tr_scaled, y_tr\n",
    "    \n",
    "     #build model\n",
    "    if model_name == 'SVM':\n",
    "        parameters = parameter\n",
    "        grid = GridSearchCV(svm.SVC(), param_grid = parameters, n_jobs = -1, refit=True, verbose=2, cv=cv)\n",
    "        grid.fit(X_tr_sampled, y_tr_sampled)\n",
    "        print(grid.best_params_)\n",
    "        model = svm.SVC(probability=True, **grid.best_params_)\n",
    "        model.fit(X_tr_sampled, y_tr_sampled)\n",
    "        y_pred = model.predict(X_te_scaled)\n",
    "    elif model_name == 'LogisticRegression':\n",
    "        parameters = parameter\n",
    "        grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid = parameters, n_jobs = -1, refit=True, verbose=2, cv=cv)\n",
    "        grid.fit(X_tr_sampled, y_tr_sampled)\n",
    "        model = LogisticRegression(max_iter=10000, **grid.best_params_)\n",
    "        model.fit(X_tr_sampled, y_tr_sampled)\n",
    "        y_pred = model.predict(X_te_scaled)\n",
    "    elif model_name == 'RandomForest':\n",
    "        parameters = parameter\n",
    "        grid = GridSearchCV(RandomForestClassifier(), param_grid = parameters, n_jobs = -1, refit=True, verbose=3, cv=cv)\n",
    "        grid.fit(X_tr_sampled, y_tr_sampled)\n",
    "        model = RandomForestClassifier(**grid.best_params_)\n",
    "        model.fit(X_tr_sampled, y_tr_sampled)\n",
    "        y_pred = model.predict(X_te_scaled)\n",
    "    else:\n",
    "        print(f'WARNING no {model} model found!')\n",
    "    \n",
    "    \n",
    "    y_score = model.predict_proba(X_te_scaled)\n",
    "    #fpr0, tpr0, thresholds = roc_curve(y_te, y_score[:, 1])\n",
    "    #roc_auc0 = auc(fpr0, tpr0)\n",
    "                   \n",
    "    \n",
    "    #print metrices    \n",
    "    result_dic = {f'Model Name': model_name,\n",
    "                  \"Model\": model,\n",
    "                  f'Balancer': balancer,\n",
    "                  f'Scaler': scaler,\n",
    "                  \"Cross-Validation Folds\": cv,\n",
    "                  f'Precision score': precision_score(y_te, y_pred, average='micro'),\n",
    "                  f'Recall score':  recall_score(y_te, y_pred, average='micro'),\n",
    "                  f'F1-score score': f1_score(y_te, y_pred, average='micro'),\n",
    "                  f'Accuracy score': accuracy_score(y_te, y_pred),\n",
    "                  #f'Area under the ROC curve (AUC)': roc_auc0,\n",
    "                  f'Grid_param': grid.best_params_,\n",
    "                  'cm': confusion_matrix(y_te, y_pred),\n",
    "                  'classification_report': classification_report(y_te, y_pred),\n",
    "                  \"y_score\": y_score, \"y_test\": y_te, \"y_pred\": y_pred}\n",
    "\n",
    "    write_pickle(path=target_file, obj=result_dic)               \n",
    "    return result_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66848cf4-f53f-43fb-ae5a-05330d131d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path did not exist: /mnt/DataRAID/melismail/PDAC/data/Classification/six_classes/celltypes/ResNet50/ResNet50_classification_dict.pkl\n",
      "SVM MinMaxScaler RandomOversampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "LogisticRegression MinMaxScaler RandomOversampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "RandomForest MinMaxScaler RandomOversampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "SVM MinMaxScaler RandomUndersampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "LogisticRegression MinMaxScaler RandomUndersampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "RandomForest MinMaxScaler RandomUndersampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "SVM MinMaxScaler  {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "LogisticRegression MinMaxScaler  {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "RandomForest MinMaxScaler  {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "SVM StandardScaler RandomOversampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV] END .................................C=1, kernel=linear; total time= 6.3min\n",
      "[CV] END .................................C=1, kernel=linear; total time= 6.3min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 6.7min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 6.8min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 7.6min\n",
      "[CV] END .................................C=1, kernel=linear; total time= 8.0min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 8.1min\n",
      "[CV] END .................................C=1, kernel=linear; total time= 8.7min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=18.8min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=18.9min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=19.0min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=20.7min\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=26.6min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=27.0min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=27.1min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=27.6min\n",
      "LogisticRegression StandardScaler RandomOversampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=111.5min\n",
      "[CV] END ....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=120.8min\n",
      "[CV] END ....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=124.2min\n",
      "[CV] END ....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=126.4min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=126.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=142.9min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 5.2min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=10.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=128.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=144.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 2.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=50.8min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=91.8min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.5min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=41.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 8.0min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 8.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=88.5min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 5.1min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 6.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=134.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 5.0min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 6.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=137.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=152.9min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 6.0min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 9.9min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=143.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 3.1min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=46.4min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 9.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=102.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.8min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=48.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=10.6min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=103.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.3min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.2min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=192.1min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 4.1min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.0min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=196.3min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 3.9min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.2min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=199.7min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.3min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.0min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=205.1min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.5min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=223.0min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 4.7min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=225.3min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=233.3min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=235.5min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 4.9min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=233.1min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=238.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 4.7min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=235.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest StandardScaler RandomOversampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.998 total time= 1.0min\n",
      "SVM StandardScaler RandomUndersampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.998 total time= 1.0min\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "LogisticRegression StandardScaler RandomUndersampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest StandardScaler RandomUndersampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "SVM StandardScaler  {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "{'C': 0.1, 'kernel': 'poly'}\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=1.000 total time= 1.5min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   7.7s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.240 total time=   0.6s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time= 1.0min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=1.000 total time= 2.6min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  19.0s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.192 total time=   0.6s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.3min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  19.1s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.200 total time=   0.6s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=1.000 total time= 3.0min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=   9.9s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.200 total time=   0.7s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=1.000 total time= 1.5min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=   9.8s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.269 total time=   0.7s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.0min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.2s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.346 total time=   0.7s\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=247.1min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time=  58.7s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.7min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  19.3s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.269 total time=   0.7s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.9s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   5.2s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.385 total time=   0.6s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=1.000 total time= 1.4min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   7.1s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.346 total time=   0.3s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.308 total time=   0.4s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=1.000 total time= 1.4min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   6.1s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.269 total time=   0.3s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.192 total time=   0.5s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   7.3s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.200 total time=   0.3s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.160 total time=   0.5s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=1.000 total time= 1.5min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   2.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   4.6s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.320 total time=   0.3s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.200 total time=   0.5s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=1.000 total time= 3.0min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  20.3s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.200 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.2min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.999 total time= 1.0min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  20.6s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.080 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.2min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=   8.6s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.120 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=   8.6s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.385 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.3min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.1min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=   9.7s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.240 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.3min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.1min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  10.8s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.231 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.3min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.999 total time= 1.5min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=   9.5s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.231 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.3min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.3min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  11.9s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.385 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.7min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.3min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  12.1s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.200 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 2.0min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.999 total time= 3.2min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  20.0s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.269 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 2.4min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time= 1.0min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=1.000 total time= 2.6min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.0s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.160 total time=   0.6s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 2.4min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.999 total time= 1.0min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   2.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   5.4s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.160 total time=   0.6s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 2.5min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.999 total time= 1.6min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  12.3s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.160 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 2.5min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=1.000 total time= 3.0min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  20.3s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.308 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 2.5min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=1.000 total time= 1.6min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.9s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   4.7s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.192 total time=   0.6s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 2.6min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.998 total time= 1.0min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=1.000 total time= 2.6min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  20.0s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.080 total time=   0.6s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression StandardScaler  {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=28.7min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=32.4min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=32.9min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=33.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=35.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=36.2min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  56.2s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  51.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  11.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   9.7s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   9.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=35.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=39.1min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  12.6s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=11.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  50.2s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  46.2s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=25.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=39.1min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 1.2min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  50.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  10.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=37.1min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  17.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=13.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=26.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.1min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=37.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  58.6s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=38.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  19.4s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=12.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=28.2min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=  10.9s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=11.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  51.8s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 1.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=27.4min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  42.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  31.5s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=51.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  42.6s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  39.6s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=51.7min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  32.8s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  52.9s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=51.7min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  26.6s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  49.9s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=53.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=  47.4s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=62.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest StandardScaler  {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  RandomOversampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.780 total time= 1.2min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=66.1min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.781 total time= 1.3min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.779 total time= 1.3min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.780 total time= 1.3min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.778 total time= 1.5min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.778 total time= 1.5min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.779 total time= 1.6min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.781 total time= 1.6min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=  50.7s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=63.1min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.780 total time=  32.8s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.777 total time= 1.4min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=65.4min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.779 total time=  31.9s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.779 total time= 1.4min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=64.8min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.778 total time=  33.4s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.780 total time= 1.4min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=65.3min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.778 total time=  31.8s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.781 total time= 1.5min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.778 total time=  46.5s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 9.6min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.779 total time=  45.6s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 9.6min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.780 total time=  48.1s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 9.5min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.779 total time=  32.5s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=11.5min\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.780 total time=  34.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=11.6min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.778 total time=  32.8s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=11.6min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.779 total time=  33.2s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=12.5min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.781 total time=  47.2s\n",
      "[CV] END .................................C=1, kernel=linear; total time=13.1min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  45.5s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=67.4min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.779 total time= 1.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=18.4min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=  46.7s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=65.4min\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.780 total time= 1.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=18.6min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.778 total time= 1.1min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=19.0min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.779 total time= 1.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=21.0min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.780 total time=  43.0s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=25.3min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.779 total time=  43.1s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=25.3min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.779 total time=  42.7s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=27.4min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.780 total time=  45.5s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=27.5min\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "LogisticRegression  RandomOversampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=24.1min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=27.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=23.3min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=27.4min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=27.0min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=24.5min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=26.0min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=26.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=25.2min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=16.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=10.8min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=27.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=33.5min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=23.8min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=32.4min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=47.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=24.3min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=33.8min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=45.4min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=38.0min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=28.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=39.3min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=15.1min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=17.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=25.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=50.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=31.4min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=89.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=124.2min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=29.7min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=98.2min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=28.0min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=102.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=132.5min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=27.8min\n",
      "[CV] END ......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=108.2min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=142.8min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=153.3min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=18.2min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=31.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=107.2min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=16.0min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=11.1min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=24.0min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=110.4min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=36.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=11.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=129.4min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=34.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=17.8min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=130.3min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=232.5min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=234.6min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=242.8min\n",
      "[CV] END ..C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=244.4min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=25.5min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=229.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=25.8min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=232.2min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=11.4min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=13.7min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=233.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=25.1min\n",
      "[CV] END ....C=1, multi_class=ovr, penalty=none, solver=sag; total time=237.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest  RandomOversampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.999 total time=  43.4s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.999 total time=  44.1s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.998 total time=  43.4s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.999 total time=  56.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  RandomUndersampler {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "LogisticRegression  RandomUndersampler {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest  RandomUndersampler {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "SVM   {'C': [0.1, 1], 'kernel': ('linear', 'poly')} 4\n",
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "{'C': 1, 'kernel': 'poly'}\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.2min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.9s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.308 total time=   0.6s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.1min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   3.4s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   5.1s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.160 total time=   0.6s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.2min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   2.5s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.240 total time=   0.2s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.346 total time=   0.5s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=1.000 total time= 1.1min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  20.6s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.200 total time=   0.6s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=1.000 total time= 1.6min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  10.5s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.160 total time=   0.6s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time=  43.8s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=1.000 total time= 2.8min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  19.7s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.385 total time=   0.6s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.3min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=  11.5s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.200 total time=   0.7s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.999 total time= 1.5min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   3.8s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.423 total time=   0.2s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.192 total time=   0.6s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time=  44.2s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.8min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  19.5s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.192 total time=   0.6s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 1.9min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  20.7s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.120 total time=   0.7s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.999 total time= 1.3min\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time=   3.7s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.231 total time=   0.3s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.200 total time=   0.6s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   2.9s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.240 total time=   0.2s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.080 total time=   0.6s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.2min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=  10.5s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.231 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 1.4min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.4s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.308 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 1.4min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=1.000 total time= 2.6min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.4s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=  11.0s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.240 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 1.4min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=1.000 total time= 2.9min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.2s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=   8.8s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.240 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.4min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.4min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=   9.4s\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.160 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.4min\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=1.000 total time= 1.4min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=   9.0s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.423 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.4min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   2.7s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.231 total time=   0.6s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 1.4min\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.9min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.6s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   3.9s\n",
      "[CV 2/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.269 total time=   0.5s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 1.4min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.999 total time= 1.4min\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  22.4s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.200 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.5min\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=1.000 total time= 1.4min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=  20.9s\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.269 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.5min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time=  45.7s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=1.000 total time= 2.9min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  21.6s\n",
      "[CV 3/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.200 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.6min\n",
      "[CV 4/4] END bootstrap=True, min_samples_split=2, n_estimators=100;, score=0.999 total time=  48.3s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.9min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=  21.3s\n",
      "[CV 2/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.385 total time=   0.3s\n",
      "[CV] END .................................C=1, kernel=linear; total time= 1.6min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=2, n_estimators=250;, score=0.999 total time= 2.6min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time=   1.3s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=  11.6s\n",
      "[CV 4/4] END bootstrap=False, min_samples_split=2, n_estimators=100;, score=0.160 total time=   0.3s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time= 1.8min\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.999 total time= 2.3min\n",
      "[CV] END ...................................C=1, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.0s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=100;, score=0.269 total time=   0.3s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time= 1.8min\n",
      "[CV 1/4] END bootstrap=False, min_samples_split=4, n_estimators=100;, score=0.999 total time= 1.5min\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=  10.7s\n",
      "[CV 1/4] END bootstrap=True, min_samples_split=4, n_estimators=250;, score=0.192 total time=   0.5s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 1.8min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=   4.1s\n",
      "[CV 3/4] END bootstrap=True, min_samples_split=2, n_estimators=250;, score=0.160 total time=   0.5s\n",
      "[CV] END ...................................C=1, kernel=poly; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression   {'penalty': ('none', 'l2'), 'C': [0.1, 1], 'multi_class': ('ovr', 'multinomial'), 'solver': ('lbfgs', 'sag')} 4\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.8min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 5.9min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.2min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time= 3.0min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 3.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 2.2min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.1min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 6.5min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.4min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 4.0min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 6.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 2.2min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time= 9.2min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time= 6.6min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.6min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=10.5min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.4min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.9min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 3.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=10.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 1.2min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time= 3.3min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 3.7min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=l2, solver=sag; total time=11.4min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time= 6.1min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=22.6min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time= 6.1min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=22.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=29.2min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 4.9min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=25.1min\n",
      "[CV] END .C=0.1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 5.6min\n",
      "[CV] END .......C=1, multi_class=ovr, penalty=l2, solver=sag; total time=24.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=31.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=32.6min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 2.2min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 5.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=25.7min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=sag; total time=33.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 2.0min\n",
      "[CV] END ...C=1, multi_class=ovr, penalty=none, solver=lbfgs; total time= 5.6min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=26.9min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 1.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=sag; total time= 2.6min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=l2, solver=lbfgs; total time= 3.3min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=28.4min\n",
      "[CV] END .....C=0.1, multi_class=ovr, penalty=l2, solver=sag; total time= 7.1min\n",
      "[CV] END C=1, multi_class=multinomial, penalty=none, solver=sag; total time=30.6min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=61.1min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=65.1min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=67.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 2.7min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=65.3min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=none, solver=lbfgs; total time= 2.6min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=65.5min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.3min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=65.0min\n",
      "[CV] END ...C=0.1, multi_class=ovr, penalty=none, solver=sag; total time=70.9min\n",
      "[CV] END C=0.1, multi_class=multinomial, penalty=l2, solver=lbfgs; total time= 3.7min\n",
      "[CV] END .....C=1, multi_class=ovr, penalty=none, solver=sag; total time=69.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest   {'n_estimators': [100, 250], 'min_samples_split': [2, 4], 'bootstrap': [True, False]} 4\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/DataRAID/melismail/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "balancer_list = ['RandomOversampler', 'RandomUndersampler', '']\n",
    "scaler_list = ['MinMaxScaler', 'StandardScaler', '']\n",
    "ml_model_list = ['SVM', 'LogisticRegression', 'RandomForest']\n",
    "parameter_list = [{'C':[0.1, 1] , 'kernel':('linear', 'poly')},\n",
    "                  {'penalty':('none', 'l2'), 'C':[0.1, 1], 'multi_class':('ovr', 'multinomial'), 'solver':('lbfgs', 'sag')},\n",
    "                  {'n_estimators':[100, 250], 'min_samples_split':[2, 4], 'bootstrap':[True, False]}]\n",
    "cv_list = [4]\n",
    "classification_dic = read_pickle(path= os.path.join(base_path, classification_path, class_path, model_path, f\"{model_path}_classification_dict.pkl\"))\n",
    "if classification_dic is not None:\n",
    "    already_done_set = {(class_dict[\"model_name\"], class_dict[\"scaler\"],  class_dict[\"balancer\"],  class_dict[\"Cross-Validation Folds\"])for class_dict in classification_dic}\n",
    "else:\n",
    "    already_done_set = set()\n",
    "    classification_dic = []\n",
    "\n",
    "new_classification_dict_list =[build_and_test(X_tr=X_train, X_te=X_test, y_tr=y_train, y_te=y_test, \n",
    "                                      plot_dir=os.path.join(base_path, plot_path, class_path, model_path), \n",
    "                                      model_name = m, scaler=s, balancer=b, parameter=p, cv=c)\n",
    "                       for s in scaler_list\n",
    "                       for b in balancer_list\n",
    "                       for m, p in zip(ml_model_list, parameter_list)\n",
    "                       for c in cv_list\n",
    "                           if (m,s,b,c) not in already_done_set]\n",
    "\n",
    "if balancer_list == 'RandomOversampler' and model_name == 'LogisticRegression':\n",
    "        reg_dic = {f'Model_Name': model_name,\n",
    "                    'Model': model,\n",
    "                   f'Balancer': balancer,\n",
    "                   f'Scaler': scaler}\n",
    "if len(new_classification_dict_list) > 0:\n",
    "    classification_dic.extend(new_classification_dict_list)\n",
    "    write_pickle(path= os.path.join(base_path, classification_path, class_path, model_path, f\"{model_path}_classification_dict.pkl\"), obj=classification_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd43e5f-3cc4-4d7c-991f-2b84bc757b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting():   \n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    \n",
    "    \n",
    "    import seaborn as sns\n",
    "    sns.heatmap(cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d391856-f5bd-4729-874d-b545a1bcdeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Balancer</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Cross-Validation Folds</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Recall score</th>\n",
       "      <th>F1-score score</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>Grid_param</th>\n",
       "      <th>cm</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[16, 5, 10, 0, 7, 35], [8, 33, 4, 0, 12, 51],...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.05934984548279961, 0.015338979145144222, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[6, 2, 6, 0, 7, 52], [3, 20, 2, 0, 14, 69], [...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[4.567822428280224e-85, 7.430012484466963e-18...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 2, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 0, 105], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.088, 0.044, 0.096, 0.004, 0.068, 0.7], [0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[17, 9, 6, 12, 9, 20], [10, 47, 8, 9, 10, 24]...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.1745602838242051, 0.11300381601015849, 0.1...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 2, 5, 0, 5, 4, 5, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[10, 20, 2, 29, 8, 4], [4, 57, 8, 25, 7, 7], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2104381796907002, 0.05547738002981127, 0.0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 4, 1, 1, 1, 0, 0, 3, 0, 4, 4, 3, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 4, 'n...</td>\n",
       "      <td>[[16, 17, 4, 15, 10, 11], [10, 54, 5, 13, 14, ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2008333333333333, 0.056666666666666664, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 5, 1, 4, 1, 4, 0, 3, 0, 2, 4, 3, 4, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06659326512912819, 0.0315491548534943, 0.0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 1, 104], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.07660305030060727, 0.030192851517621053, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 4, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 4, 0, 0, 0, 104], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.050666666666666665, 0.012000000000000002, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[13, 5, 5, 0, 5, 45], [9, 34, 5, 0, 11, 49], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.14759242397658648, 0.04160048403593633, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 0, 5, 4, 5, 0, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[6, 3, 4, 0, 8, 52], [5, 24, 4, 0, 10, 65], [...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[5.398682143291396e-24, 1.8502616993270508e-2...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 4, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.11, 0.01, 0.09, 0.0, 0.07, 0.72], [0.04, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[12, 12, 4, 9, 11, 25], [9, 44, 9, 8, 17, 21]...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.18985154883075198, 0.12583256951107866, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 4, 5, 0, 5, 4, 0, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'multinomial', 'pena...</td>\n",
       "      <td>[[13, 15, 4, 16, 11, 14], [10, 48, 11, 13, 9, ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.019940528905008883, 0.006000073372682604, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 0, 5, 0, 4, 4, 0, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[13, 19, 7, 23, 8, 3], [5, 54, 6, 21, 17, 5],...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2, 0.06, 0.03, 0.42, 0.08, 0.21], [0.13, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 4, 1, 4, 1, 0, 0, 3, 4, 4, 1, 3, 5, 1, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=0.1, kernel='poly', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.04491784468518942, 0.04667972762414204, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[2, 1, 3, 0, 2, 65], [2, 17, 2, 0, 3, 84], [1...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06661946393527071, 0.023967642168839908, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.04, 0.02, 0.028, 0.0, 0.052, 0.86], [0.064...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[13, 5, 7, 0, 5, 43], [9, 23, 3, 0, 11, 62], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.016625275369202608, 0.004801875575205476, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 2, 5, 4, 0, 1, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[11, 2, 9, 0, 6, 45], [2, 20, 5, 0, 13, 68], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.0, 3.5829105274799856e-33, 1.3168056063782...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 4, 5, 2, 5, 5, 5, 5, 2, 5, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 4, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 0, 0, 0, 0, 108], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.08, 0.05, 0.08, 0.0, 0.04, 0.75], [0.04, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[17, 6, 11, 12, 13, 14], [15, 36, 8, 5, 17, 2...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.1634290343631124, 0.13076197985365098, 0.1...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 0, 5, 0, 5, 4, 5, 0, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[21, 10, 2, 14, 12, 14], [12, 40, 7, 8, 14, 2...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2509056120917213, 0.043827938408403586, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 2, 5, 1, 0, 0, 5, 0, 4, 4, 5, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[13, 20, 5, 18, 7, 10], [11, 60, 2, 14, 10, 1...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.21, 0.06, 0.06, 0.36, 0.07, 0.24], [0.13, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 1, 1, 4, 1, 4, 2, 5, 3, 4, 2, 3, 4, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(C=1, kernel='poly', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.05936471579474457, 0.031403242392438205, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[3, 1, 0, 0, 0, 69], [0, 9, 0, 0, 0, 99], [0,...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06802042125765148, 0.033437958827629594, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.048, 0.036, 0.048, 0.0, 0.064, 0.804], [0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name                                              Model  \\\n",
       "0                  SVM        SVC(C=1, kernel='linear', probability=True)   \n",
       "1   LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "2         RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3                  SVM        SVC(C=1, kernel='linear', probability=True)   \n",
       "4   LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "5         RandomForest  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "6                  SVM      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "7   LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "8         RandomForest  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "9                  SVM        SVC(C=1, kernel='linear', probability=True)   \n",
       "10  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "11        RandomForest  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "12                 SVM      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "13  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "14        RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "15                 SVM        SVC(C=0.1, kernel='poly', probability=True)   \n",
       "16  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "17        RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "18                 SVM        SVC(C=1, kernel='linear', probability=True)   \n",
       "19  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "20        RandomForest  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "21                 SVM      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "22  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "23        RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "24                 SVM          SVC(C=1, kernel='poly', probability=True)   \n",
       "25  LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "26        RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "\n",
       "              Balancer          Scaler  Cross-Validation Folds  \\\n",
       "0    RandomOversampler    MinMaxScaler                       4   \n",
       "1    RandomOversampler    MinMaxScaler                       4   \n",
       "2    RandomOversampler    MinMaxScaler                       4   \n",
       "3   RandomUndersampler    MinMaxScaler                       4   \n",
       "4   RandomUndersampler    MinMaxScaler                       4   \n",
       "5   RandomUndersampler    MinMaxScaler                       4   \n",
       "6                         MinMaxScaler                       4   \n",
       "7                         MinMaxScaler                       4   \n",
       "8                         MinMaxScaler                       4   \n",
       "9    RandomOversampler  StandardScaler                       4   \n",
       "10   RandomOversampler  StandardScaler                       4   \n",
       "11   RandomOversampler  StandardScaler                       4   \n",
       "12  RandomUndersampler  StandardScaler                       4   \n",
       "13  RandomUndersampler  StandardScaler                       4   \n",
       "14  RandomUndersampler  StandardScaler                       4   \n",
       "15                      StandardScaler                       4   \n",
       "16                      StandardScaler                       4   \n",
       "17                      StandardScaler                       4   \n",
       "18   RandomOversampler                                       4   \n",
       "19   RandomOversampler                                       4   \n",
       "20   RandomOversampler                                       4   \n",
       "21  RandomUndersampler                                       4   \n",
       "22  RandomUndersampler                                       4   \n",
       "23  RandomUndersampler                                       4   \n",
       "24                                                           4   \n",
       "25                                                           4   \n",
       "26                                                           4   \n",
       "\n",
       "    Precision score  Recall score  F1-score score  Accuracy score  \\\n",
       "0          0.530844      0.530844        0.530844        0.530844   \n",
       "1          0.613095      0.613095        0.613095        0.613095   \n",
       "2          0.776515      0.776515        0.776515        0.776515   \n",
       "3          0.204004      0.204004        0.204004        0.204004   \n",
       "4          0.136364      0.136364        0.136364        0.136364   \n",
       "5          0.163961      0.163961        0.163961        0.163961   \n",
       "6          0.776515      0.776515        0.776515        0.776515   \n",
       "7          0.776515      0.776515        0.776515        0.776515   \n",
       "8          0.777056      0.777056        0.777056        0.777056   \n",
       "9          0.582792      0.582792        0.582792        0.582792   \n",
       "10         0.623377      0.623377        0.623377        0.623377   \n",
       "11         0.776515      0.776515        0.776515        0.776515   \n",
       "12         0.227273      0.227273        0.227273        0.227273   \n",
       "13         0.171537      0.171537        0.171537        0.171537   \n",
       "14         0.123377      0.123377        0.123377        0.123377   \n",
       "15         0.774892      0.774892        0.774892        0.774892   \n",
       "16         0.711039      0.711039        0.711039        0.711039   \n",
       "17         0.775974      0.775974        0.775974        0.775974   \n",
       "18         0.552489      0.552489        0.552489        0.552489   \n",
       "19         0.600649      0.600649        0.600649        0.600649   \n",
       "20         0.774892      0.774892        0.774892        0.774892   \n",
       "21         0.187229      0.187229        0.187229        0.187229   \n",
       "22         0.200216      0.200216        0.200216        0.200216   \n",
       "23         0.150974      0.150974        0.150974        0.150974   \n",
       "24         0.775433      0.775433        0.775433        0.775433   \n",
       "25         0.764610      0.764610        0.764610        0.764610   \n",
       "26         0.775974      0.775974        0.775974        0.775974   \n",
       "\n",
       "                                           Grid_param  \\\n",
       "0                        {'C': 1, 'kernel': 'linear'}   \n",
       "1   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "2   {'bootstrap': False, 'min_samples_split': 2, '...   \n",
       "3                        {'C': 1, 'kernel': 'linear'}   \n",
       "4   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "5   {'bootstrap': True, 'min_samples_split': 4, 'n...   \n",
       "6                      {'C': 0.1, 'kernel': 'linear'}   \n",
       "7   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "8   {'bootstrap': True, 'min_samples_split': 4, 'n...   \n",
       "9                        {'C': 1, 'kernel': 'linear'}   \n",
       "10  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "11  {'bootstrap': False, 'min_samples_split': 4, '...   \n",
       "12                     {'C': 0.1, 'kernel': 'linear'}   \n",
       "13  {'C': 0.1, 'multi_class': 'multinomial', 'pena...   \n",
       "14  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "15                       {'C': 0.1, 'kernel': 'poly'}   \n",
       "16  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "17  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "18                       {'C': 1, 'kernel': 'linear'}   \n",
       "19  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "20  {'bootstrap': False, 'min_samples_split': 4, '...   \n",
       "21                     {'C': 0.1, 'kernel': 'linear'}   \n",
       "22  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "23  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "24                         {'C': 1, 'kernel': 'poly'}   \n",
       "25  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "26  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "\n",
       "                                                   cm  \\\n",
       "0   [[16, 5, 10, 0, 7, 35], [8, 33, 4, 0, 12, 51],...   \n",
       "1   [[6, 2, 6, 0, 7, 52], [3, 20, 2, 0, 14, 69], [...   \n",
       "2   [[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 0, 105], [0...   \n",
       "3   [[17, 9, 6, 12, 9, 20], [10, 47, 8, 9, 10, 24]...   \n",
       "4   [[10, 20, 2, 29, 8, 4], [4, 57, 8, 25, 7, 7], ...   \n",
       "5   [[16, 17, 4, 15, 10, 11], [10, 54, 5, 13, 14, ...   \n",
       "6   [[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...   \n",
       "7   [[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 1, 104], [0...   \n",
       "8   [[0, 1, 0, 0, 0, 72], [0, 4, 0, 0, 0, 104], [0...   \n",
       "9   [[13, 5, 5, 0, 5, 45], [9, 34, 5, 0, 11, 49], ...   \n",
       "10  [[6, 3, 4, 0, 8, 52], [5, 24, 4, 0, 10, 65], [...   \n",
       "11  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "12  [[12, 12, 4, 9, 11, 25], [9, 44, 9, 8, 17, 21]...   \n",
       "13  [[13, 15, 4, 16, 11, 14], [10, 48, 11, 13, 9, ...   \n",
       "14  [[13, 19, 7, 23, 8, 3], [5, 54, 6, 21, 17, 5],...   \n",
       "15  [[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...   \n",
       "16  [[2, 1, 3, 0, 2, 65], [2, 17, 2, 0, 3, 84], [1...   \n",
       "17  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "18  [[13, 5, 7, 0, 5, 43], [9, 23, 3, 0, 11, 62], ...   \n",
       "19  [[11, 2, 9, 0, 6, 45], [2, 20, 5, 0, 13, 68], ...   \n",
       "20  [[0, 1, 0, 0, 0, 72], [0, 0, 0, 0, 0, 108], [0...   \n",
       "21  [[17, 6, 11, 12, 13, 14], [15, 36, 8, 5, 17, 2...   \n",
       "22  [[21, 10, 2, 14, 12, 14], [12, 40, 7, 8, 14, 2...   \n",
       "23  [[13, 20, 5, 18, 7, 10], [11, 60, 2, 14, 10, 1...   \n",
       "24  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "25  [[3, 1, 0, 0, 0, 69], [0, 9, 0, 0, 0, 99], [0,...   \n",
       "26  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "\n",
       "                                classification_report  \\\n",
       "0                 precision    recall  f1-score   ...   \n",
       "1                 precision    recall  f1-score   ...   \n",
       "2                 precision    recall  f1-score   ...   \n",
       "3                 precision    recall  f1-score   ...   \n",
       "4                 precision    recall  f1-score   ...   \n",
       "5                 precision    recall  f1-score   ...   \n",
       "6                 precision    recall  f1-score   ...   \n",
       "7                 precision    recall  f1-score   ...   \n",
       "8                 precision    recall  f1-score   ...   \n",
       "9                 precision    recall  f1-score   ...   \n",
       "10                precision    recall  f1-score   ...   \n",
       "11                precision    recall  f1-score   ...   \n",
       "12                precision    recall  f1-score   ...   \n",
       "13                precision    recall  f1-score   ...   \n",
       "14                precision    recall  f1-score   ...   \n",
       "15                precision    recall  f1-score   ...   \n",
       "16                precision    recall  f1-score   ...   \n",
       "17                precision    recall  f1-score   ...   \n",
       "18                precision    recall  f1-score   ...   \n",
       "19                precision    recall  f1-score   ...   \n",
       "20                precision    recall  f1-score   ...   \n",
       "21                precision    recall  f1-score   ...   \n",
       "22                precision    recall  f1-score   ...   \n",
       "23                precision    recall  f1-score   ...   \n",
       "24                precision    recall  f1-score   ...   \n",
       "25                precision    recall  f1-score   ...   \n",
       "26                precision    recall  f1-score   ...   \n",
       "\n",
       "                                              y_score  \\\n",
       "0   [[0.05934984548279961, 0.015338979145144222, 0...   \n",
       "1   [[4.567822428280224e-85, 7.430012484466963e-18...   \n",
       "2   [[0.088, 0.044, 0.096, 0.004, 0.068, 0.7], [0....   \n",
       "3   [[0.1745602838242051, 0.11300381601015849, 0.1...   \n",
       "4   [[0.2104381796907002, 0.05547738002981127, 0.0...   \n",
       "5   [[0.2008333333333333, 0.056666666666666664, 0....   \n",
       "6   [[0.06659326512912819, 0.0315491548534943, 0.0...   \n",
       "7   [[0.07660305030060727, 0.030192851517621053, 0...   \n",
       "8   [[0.050666666666666665, 0.012000000000000002, ...   \n",
       "9   [[0.14759242397658648, 0.04160048403593633, 0....   \n",
       "10  [[5.398682143291396e-24, 1.8502616993270508e-2...   \n",
       "11  [[0.11, 0.01, 0.09, 0.0, 0.07, 0.72], [0.04, 0...   \n",
       "12  [[0.18985154883075198, 0.12583256951107866, 0....   \n",
       "13  [[0.019940528905008883, 0.006000073372682604, ...   \n",
       "14  [[0.2, 0.06, 0.03, 0.42, 0.08, 0.21], [0.13, 0...   \n",
       "15  [[0.04491784468518942, 0.04667972762414204, 0....   \n",
       "16  [[0.06661946393527071, 0.023967642168839908, 0...   \n",
       "17  [[0.04, 0.02, 0.028, 0.0, 0.052, 0.86], [0.064...   \n",
       "18  [[0.016625275369202608, 0.004801875575205476, ...   \n",
       "19  [[0.0, 3.5829105274799856e-33, 1.3168056063782...   \n",
       "20  [[0.08, 0.05, 0.08, 0.0, 0.04, 0.75], [0.04, 0...   \n",
       "21  [[0.1634290343631124, 0.13076197985365098, 0.1...   \n",
       "22  [[0.2509056120917213, 0.043827938408403586, 0....   \n",
       "23  [[0.21, 0.06, 0.06, 0.36, 0.07, 0.24], [0.13, ...   \n",
       "24  [[0.05936471579474457, 0.031403242392438205, 0...   \n",
       "25  [[0.06802042125765148, 0.033437958827629594, 0...   \n",
       "26  [[0.048, 0.036, 0.048, 0.0, 0.064, 0.804], [0....   \n",
       "\n",
       "                                               y_test  \\\n",
       "0   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "1   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "2   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "3   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "4   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "5   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "6   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "7   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "8   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "9   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "10  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "11  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "12  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "13  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "14  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "15  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "16  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "17  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "18  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "19  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "20  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "21  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "22  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "23  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "24  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "25  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "26  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "\n",
       "                                               y_pred  \n",
       "0   [2, 1, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2, 5, 5, 5, ...  \n",
       "1   [2, 1, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, ...  \n",
       "2   [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "3   [5, 4, 2, 5, 1, 0, 2, 5, 0, 5, 4, 5, 4, 4, 5, ...  \n",
       "4   [3, 4, 1, 1, 1, 0, 0, 3, 0, 4, 4, 3, 4, 4, 4, ...  \n",
       "5   [3, 5, 1, 4, 1, 4, 0, 3, 0, 2, 4, 3, 4, 2, 4, ...  \n",
       "6   [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "7   [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "8   [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "9   [2, 1, 5, 5, 5, 5, 0, 5, 0, 5, 4, 5, 0, 5, 5, ...  \n",
       "10  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "11  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "12  [5, 4, 2, 5, 1, 0, 4, 5, 0, 5, 4, 0, 4, 4, 5, ...  \n",
       "13  [5, 4, 2, 5, 1, 0, 0, 5, 0, 4, 4, 0, 4, 4, 5, ...  \n",
       "14  [3, 4, 1, 4, 1, 0, 0, 3, 4, 4, 1, 3, 5, 1, 4, ...  \n",
       "15  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "16  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "17  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "18  [2, 1, 5, 5, 5, 5, 0, 5, 2, 5, 4, 0, 1, 5, 5, ...  \n",
       "19  [5, 1, 5, 5, 4, 5, 2, 5, 5, 5, 5, 2, 5, 5, 4, ...  \n",
       "20  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "21  [5, 4, 2, 5, 1, 0, 0, 5, 0, 5, 4, 5, 0, 4, 5, ...  \n",
       "22  [5, 1, 2, 5, 1, 0, 0, 5, 0, 4, 4, 5, 4, 4, 5, ...  \n",
       "23  [3, 1, 1, 4, 1, 4, 2, 5, 3, 4, 2, 3, 4, 2, 4, ...  \n",
       "24  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "25  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "26  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification = pd.DataFrame(classification_dic)\n",
    "df_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768736d9-0600-494f-9951-f82428cdc665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Balancer</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Cross-Validation Folds</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Recall score</th>\n",
       "      <th>F1-score score</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>Grid_param</th>\n",
       "      <th>cm</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[13, 19, 7, 23, 8, 3], [5, 54, 6, 21, 17, 5],...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2, 0.06, 0.03, 0.42, 0.08, 0.21], [0.13, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 4, 1, 4, 1, 0, 0, 3, 4, 4, 1, 3, 5, 1, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[10, 20, 2, 29, 8, 4], [4, 57, 8, 25, 7, 7], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2104381796907002, 0.05547738002981127, 0.0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 4, 1, 1, 1, 0, 0, 3, 0, 4, 4, 3, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>0.150974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[13, 20, 5, 18, 7, 10], [11, 60, 2, 14, 10, 1...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.21, 0.06, 0.06, 0.36, 0.07, 0.24], [0.13, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 1, 1, 4, 1, 4, 2, 5, 3, 4, 2, 3, 4, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 4, 'n...</td>\n",
       "      <td>[[16, 17, 4, 15, 10, 11], [10, 54, 5, 13, 14, ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2008333333333333, 0.056666666666666664, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[3, 5, 1, 4, 1, 4, 0, 3, 0, 2, 4, 3, 4, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'multinomial', 'pena...</td>\n",
       "      <td>[[13, 15, 4, 16, 11, 14], [10, 48, 11, 13, 9, ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.019940528905008883, 0.006000073372682604, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 0, 5, 0, 4, 4, 0, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>0.187229</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[17, 6, 11, 12, 13, 14], [15, 36, 8, 5, 17, 2...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.1634290343631124, 0.13076197985365098, 0.1...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 0, 5, 0, 5, 4, 5, 0, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>0.200216</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[21, 10, 2, 14, 12, 14], [12, 40, 7, 8, 14, 2...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.2509056120917213, 0.043827938408403586, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 2, 5, 1, 0, 0, 5, 0, 4, 4, 5, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>0.204004</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[17, 9, 6, 12, 9, 20], [10, 47, 8, 9, 10, 24]...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.1745602838242051, 0.11300381601015849, 0.1...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 2, 5, 0, 5, 4, 5, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomUndersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[12, 12, 4, 9, 11, 25], [9, 44, 9, 8, 17, 21]...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.18985154883075198, 0.12583256951107866, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 4, 2, 5, 1, 0, 4, 5, 0, 5, 4, 0, 4, 4, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[16, 5, 10, 0, 7, 35], [8, 33, 4, 0, 12, 51],...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.05934984548279961, 0.015338979145144222, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>0.552489</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[13, 5, 7, 0, 5, 43], [9, 23, 3, 0, 11, 62], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.016625275369202608, 0.004801875575205476, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 2, 5, 4, 0, 1, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=1, kernel='linear', probability=True)</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>0.582792</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>[[13, 5, 5, 0, 5, 45], [9, 34, 5, 0, 11, 49], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.14759242397658648, 0.04160048403593633, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 0, 5, 0, 5, 4, 5, 0, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[11, 2, 9, 0, 6, 45], [2, 20, 5, 0, 13, 68], ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.0, 3.5829105274799856e-33, 1.3168056063782...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 4, 5, 2, 5, 5, 5, 5, 2, 5, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[6, 2, 6, 0, 7, 52], [3, 20, 2, 0, 14, 69], [...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[4.567822428280224e-85, 7.430012484466963e-18...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2, 1, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...</td>\n",
       "      <td>[[6, 3, 4, 0, 8, 52], [5, 24, 4, 0, 10, 65], [...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[5.398682143291396e-24, 1.8502616993270508e-2...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[2, 1, 3, 0, 2, 65], [2, 17, 2, 0, 3, 84], [1...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06661946393527071, 0.023967642168839908, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=10000, mult...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>0.764610</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[3, 1, 0, 0, 0, 69], [0, 9, 0, 0, 0, 99], [0,...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06802042125765148, 0.033437958827629594, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=0.1, kernel='poly', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.04491784468518942, 0.04667972762414204, 0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 4, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 0, 0, 0, 0, 108], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.08, 0.05, 0.08, 0.0, 0.04, 0.75], [0.04, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=1, kernel='poly', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.05936471579474457, 0.031403242392438205, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td></td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.04, 0.02, 0.028, 0.0, 0.052, 0.86], [0.064...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 2, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.048, 0.036, 0.048, 0.0, 0.064, 0.804], [0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=0.1, kernel='linear', probability=True)</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.06659326512912819, 0.0315491548534943, 0.0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 2, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 0, 105], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.088, 0.044, 0.096, 0.004, 0.068, 0.7], [0....</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td>RandomOversampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'bootstrap': False, 'min_samples_split': 4, '...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.11, 0.01, 0.09, 0.0, 0.07, 0.72], [0.04, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=0.1, max_iter=5000, multi...</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 1, 104], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.07660305030060727, 0.030192851517621053, 0...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "      <td></td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>{'bootstrap': True, 'min_samples_split': 4, 'n...</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 72], [0, 4, 0, 0, 0, 104], [0...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>[[0.050666666666666665, 0.012000000000000002, ...</td>\n",
       "      <td>[5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name                                              Model  \\\n",
       "0   RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "1       LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "2   RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3   RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "4       LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "5                      SVC      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "6       LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "7                      SVC        SVC(C=1, kernel='linear', probability=True)   \n",
       "8                      SVC      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "9                      SVC        SVC(C=1, kernel='linear', probability=True)   \n",
       "10                     SVC        SVC(C=1, kernel='linear', probability=True)   \n",
       "11                     SVC        SVC(C=1, kernel='linear', probability=True)   \n",
       "12      LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "13      LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "14      LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "15      LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "16      LogisticRegression  LogisticRegression(C=0.1, max_iter=10000, mult...   \n",
       "17                     SVC        SVC(C=0.1, kernel='poly', probability=True)   \n",
       "18  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "19                     SVC          SVC(C=1, kernel='poly', probability=True)   \n",
       "20  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "21  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "22                     SVC      SVC(C=0.1, kernel='linear', probability=True)   \n",
       "23  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "24  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "25      LogisticRegression  LogisticRegression(C=0.1, max_iter=5000, multi...   \n",
       "26  RandomForestClassifier  (DecisionTreeClassifier(max_features='sqrt', m...   \n",
       "\n",
       "              Balancer          Scaler  Cross-Validation Folds  \\\n",
       "0   RandomUndersampler  StandardScaler                       4   \n",
       "1   RandomUndersampler    MinMaxScaler                       4   \n",
       "2   RandomUndersampler                                       4   \n",
       "3   RandomUndersampler    MinMaxScaler                       4   \n",
       "4   RandomUndersampler  StandardScaler                       4   \n",
       "5   RandomUndersampler                                       4   \n",
       "6   RandomUndersampler                                       4   \n",
       "7   RandomUndersampler    MinMaxScaler                       4   \n",
       "8   RandomUndersampler  StandardScaler                       4   \n",
       "9    RandomOversampler    MinMaxScaler                       4   \n",
       "10   RandomOversampler                                       4   \n",
       "11   RandomOversampler  StandardScaler                       4   \n",
       "12   RandomOversampler                                       4   \n",
       "13   RandomOversampler    MinMaxScaler                       4   \n",
       "14   RandomOversampler  StandardScaler                       4   \n",
       "15                      StandardScaler                       4   \n",
       "16                                                           4   \n",
       "17                      StandardScaler                       4   \n",
       "18   RandomOversampler                                       4   \n",
       "19                                                           4   \n",
       "20                      StandardScaler                       4   \n",
       "21                                                           4   \n",
       "22                        MinMaxScaler                       4   \n",
       "23   RandomOversampler    MinMaxScaler                       4   \n",
       "24   RandomOversampler  StandardScaler                       4   \n",
       "25                        MinMaxScaler                       4   \n",
       "26                        MinMaxScaler                       4   \n",
       "\n",
       "    Precision score  Recall score  F1-score score  Accuracy score  \\\n",
       "0          0.123377      0.123377        0.123377        0.123377   \n",
       "1          0.136364      0.136364        0.136364        0.136364   \n",
       "2          0.150974      0.150974        0.150974        0.150974   \n",
       "3          0.163961      0.163961        0.163961        0.163961   \n",
       "4          0.171537      0.171537        0.171537        0.171537   \n",
       "5          0.187229      0.187229        0.187229        0.187229   \n",
       "6          0.200216      0.200216        0.200216        0.200216   \n",
       "7          0.204004      0.204004        0.204004        0.204004   \n",
       "8          0.227273      0.227273        0.227273        0.227273   \n",
       "9          0.530844      0.530844        0.530844        0.530844   \n",
       "10         0.552489      0.552489        0.552489        0.552489   \n",
       "11         0.582792      0.582792        0.582792        0.582792   \n",
       "12         0.600649      0.600649        0.600649        0.600649   \n",
       "13         0.613095      0.613095        0.613095        0.613095   \n",
       "14         0.623377      0.623377        0.623377        0.623377   \n",
       "15         0.711039      0.711039        0.711039        0.711039   \n",
       "16         0.764610      0.764610        0.764610        0.764610   \n",
       "17         0.774892      0.774892        0.774892        0.774892   \n",
       "18         0.774892      0.774892        0.774892        0.774892   \n",
       "19         0.775433      0.775433        0.775433        0.775433   \n",
       "20         0.775974      0.775974        0.775974        0.775974   \n",
       "21         0.775974      0.775974        0.775974        0.775974   \n",
       "22         0.776515      0.776515        0.776515        0.776515   \n",
       "23         0.776515      0.776515        0.776515        0.776515   \n",
       "24         0.776515      0.776515        0.776515        0.776515   \n",
       "25         0.776515      0.776515        0.776515        0.776515   \n",
       "26         0.777056      0.777056        0.777056        0.777056   \n",
       "\n",
       "                                           Grid_param  \\\n",
       "0   {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "1   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "2   {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "3   {'bootstrap': True, 'min_samples_split': 4, 'n...   \n",
       "4   {'C': 0.1, 'multi_class': 'multinomial', 'pena...   \n",
       "5                      {'C': 0.1, 'kernel': 'linear'}   \n",
       "6   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "7                        {'C': 1, 'kernel': 'linear'}   \n",
       "8                      {'C': 0.1, 'kernel': 'linear'}   \n",
       "9                        {'C': 1, 'kernel': 'linear'}   \n",
       "10                       {'C': 1, 'kernel': 'linear'}   \n",
       "11                       {'C': 1, 'kernel': 'linear'}   \n",
       "12  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "13  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "14  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'n...   \n",
       "15  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "16  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "17                       {'C': 0.1, 'kernel': 'poly'}   \n",
       "18  {'bootstrap': False, 'min_samples_split': 4, '...   \n",
       "19                         {'C': 1, 'kernel': 'poly'}   \n",
       "20  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "21  {'bootstrap': True, 'min_samples_split': 2, 'n...   \n",
       "22                     {'C': 0.1, 'kernel': 'linear'}   \n",
       "23  {'bootstrap': False, 'min_samples_split': 2, '...   \n",
       "24  {'bootstrap': False, 'min_samples_split': 4, '...   \n",
       "25  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...   \n",
       "26  {'bootstrap': True, 'min_samples_split': 4, 'n...   \n",
       "\n",
       "                                                   cm  \\\n",
       "0   [[13, 19, 7, 23, 8, 3], [5, 54, 6, 21, 17, 5],...   \n",
       "1   [[10, 20, 2, 29, 8, 4], [4, 57, 8, 25, 7, 7], ...   \n",
       "2   [[13, 20, 5, 18, 7, 10], [11, 60, 2, 14, 10, 1...   \n",
       "3   [[16, 17, 4, 15, 10, 11], [10, 54, 5, 13, 14, ...   \n",
       "4   [[13, 15, 4, 16, 11, 14], [10, 48, 11, 13, 9, ...   \n",
       "5   [[17, 6, 11, 12, 13, 14], [15, 36, 8, 5, 17, 2...   \n",
       "6   [[21, 10, 2, 14, 12, 14], [12, 40, 7, 8, 14, 2...   \n",
       "7   [[17, 9, 6, 12, 9, 20], [10, 47, 8, 9, 10, 24]...   \n",
       "8   [[12, 12, 4, 9, 11, 25], [9, 44, 9, 8, 17, 21]...   \n",
       "9   [[16, 5, 10, 0, 7, 35], [8, 33, 4, 0, 12, 51],...   \n",
       "10  [[13, 5, 7, 0, 5, 43], [9, 23, 3, 0, 11, 62], ...   \n",
       "11  [[13, 5, 5, 0, 5, 45], [9, 34, 5, 0, 11, 49], ...   \n",
       "12  [[11, 2, 9, 0, 6, 45], [2, 20, 5, 0, 13, 68], ...   \n",
       "13  [[6, 2, 6, 0, 7, 52], [3, 20, 2, 0, 14, 69], [...   \n",
       "14  [[6, 3, 4, 0, 8, 52], [5, 24, 4, 0, 10, 65], [...   \n",
       "15  [[2, 1, 3, 0, 2, 65], [2, 17, 2, 0, 3, 84], [1...   \n",
       "16  [[3, 1, 0, 0, 0, 69], [0, 9, 0, 0, 0, 99], [0,...   \n",
       "17  [[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...   \n",
       "18  [[0, 1, 0, 0, 0, 72], [0, 0, 0, 0, 0, 108], [0...   \n",
       "19  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "20  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "21  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "22  [[0, 0, 0, 0, 0, 73], [0, 1, 0, 0, 0, 107], [0...   \n",
       "23  [[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 0, 105], [0...   \n",
       "24  [[0, 1, 0, 0, 0, 72], [0, 2, 0, 0, 0, 106], [0...   \n",
       "25  [[0, 1, 0, 0, 0, 72], [0, 3, 0, 0, 1, 104], [0...   \n",
       "26  [[0, 1, 0, 0, 0, 72], [0, 4, 0, 0, 0, 104], [0...   \n",
       "\n",
       "                                classification_report  \\\n",
       "0                 precision    recall  f1-score   ...   \n",
       "1                 precision    recall  f1-score   ...   \n",
       "2                 precision    recall  f1-score   ...   \n",
       "3                 precision    recall  f1-score   ...   \n",
       "4                 precision    recall  f1-score   ...   \n",
       "5                 precision    recall  f1-score   ...   \n",
       "6                 precision    recall  f1-score   ...   \n",
       "7                 precision    recall  f1-score   ...   \n",
       "8                 precision    recall  f1-score   ...   \n",
       "9                 precision    recall  f1-score   ...   \n",
       "10                precision    recall  f1-score   ...   \n",
       "11                precision    recall  f1-score   ...   \n",
       "12                precision    recall  f1-score   ...   \n",
       "13                precision    recall  f1-score   ...   \n",
       "14                precision    recall  f1-score   ...   \n",
       "15                precision    recall  f1-score   ...   \n",
       "16                precision    recall  f1-score   ...   \n",
       "17                precision    recall  f1-score   ...   \n",
       "18                precision    recall  f1-score   ...   \n",
       "19                precision    recall  f1-score   ...   \n",
       "20                precision    recall  f1-score   ...   \n",
       "21                precision    recall  f1-score   ...   \n",
       "22                precision    recall  f1-score   ...   \n",
       "23                precision    recall  f1-score   ...   \n",
       "24                precision    recall  f1-score   ...   \n",
       "25                precision    recall  f1-score   ...   \n",
       "26                precision    recall  f1-score   ...   \n",
       "\n",
       "                                              y_score  \\\n",
       "0   [[0.2, 0.06, 0.03, 0.42, 0.08, 0.21], [0.13, 0...   \n",
       "1   [[0.2104381796907002, 0.05547738002981127, 0.0...   \n",
       "2   [[0.21, 0.06, 0.06, 0.36, 0.07, 0.24], [0.13, ...   \n",
       "3   [[0.2008333333333333, 0.056666666666666664, 0....   \n",
       "4   [[0.019940528905008883, 0.006000073372682604, ...   \n",
       "5   [[0.1634290343631124, 0.13076197985365098, 0.1...   \n",
       "6   [[0.2509056120917213, 0.043827938408403586, 0....   \n",
       "7   [[0.1745602838242051, 0.11300381601015849, 0.1...   \n",
       "8   [[0.18985154883075198, 0.12583256951107866, 0....   \n",
       "9   [[0.05934984548279961, 0.015338979145144222, 0...   \n",
       "10  [[0.016625275369202608, 0.004801875575205476, ...   \n",
       "11  [[0.14759242397658648, 0.04160048403593633, 0....   \n",
       "12  [[0.0, 3.5829105274799856e-33, 1.3168056063782...   \n",
       "13  [[4.567822428280224e-85, 7.430012484466963e-18...   \n",
       "14  [[5.398682143291396e-24, 1.8502616993270508e-2...   \n",
       "15  [[0.06661946393527071, 0.023967642168839908, 0...   \n",
       "16  [[0.06802042125765148, 0.033437958827629594, 0...   \n",
       "17  [[0.04491784468518942, 0.04667972762414204, 0....   \n",
       "18  [[0.08, 0.05, 0.08, 0.0, 0.04, 0.75], [0.04, 0...   \n",
       "19  [[0.05936471579474457, 0.031403242392438205, 0...   \n",
       "20  [[0.04, 0.02, 0.028, 0.0, 0.052, 0.86], [0.064...   \n",
       "21  [[0.048, 0.036, 0.048, 0.0, 0.064, 0.804], [0....   \n",
       "22  [[0.06659326512912819, 0.0315491548534943, 0.0...   \n",
       "23  [[0.088, 0.044, 0.096, 0.004, 0.068, 0.7], [0....   \n",
       "24  [[0.11, 0.01, 0.09, 0.0, 0.07, 0.72], [0.04, 0...   \n",
       "25  [[0.07660305030060727, 0.030192851517621053, 0...   \n",
       "26  [[0.050666666666666665, 0.012000000000000002, ...   \n",
       "\n",
       "                                               y_test  \\\n",
       "0   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "1   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "2   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "3   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "4   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "5   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "6   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "7   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "8   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "9   [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "10  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "11  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "12  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "13  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "14  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "15  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "16  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "17  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "18  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "19  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "20  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "21  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "22  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "23  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "24  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "25  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "26  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "\n",
       "                                               y_pred  \n",
       "0   [3, 4, 1, 4, 1, 0, 0, 3, 4, 4, 1, 3, 5, 1, 4, ...  \n",
       "1   [3, 4, 1, 1, 1, 0, 0, 3, 0, 4, 4, 3, 4, 4, 4, ...  \n",
       "2   [3, 1, 1, 4, 1, 4, 2, 5, 3, 4, 2, 3, 4, 2, 4, ...  \n",
       "3   [3, 5, 1, 4, 1, 4, 0, 3, 0, 2, 4, 3, 4, 2, 4, ...  \n",
       "4   [5, 4, 2, 5, 1, 0, 0, 5, 0, 4, 4, 0, 4, 4, 5, ...  \n",
       "5   [5, 4, 2, 5, 1, 0, 0, 5, 0, 5, 4, 5, 0, 4, 5, ...  \n",
       "6   [5, 1, 2, 5, 1, 0, 0, 5, 0, 4, 4, 5, 4, 4, 5, ...  \n",
       "7   [5, 4, 2, 5, 1, 0, 2, 5, 0, 5, 4, 5, 4, 4, 5, ...  \n",
       "8   [5, 4, 2, 5, 1, 0, 4, 5, 0, 5, 4, 0, 4, 4, 5, ...  \n",
       "9   [2, 1, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2, 5, 5, 5, ...  \n",
       "10  [2, 1, 5, 5, 5, 5, 0, 5, 2, 5, 4, 0, 1, 5, 5, ...  \n",
       "11  [2, 1, 5, 5, 5, 5, 0, 5, 0, 5, 4, 5, 0, 5, 5, ...  \n",
       "12  [5, 1, 5, 5, 4, 5, 2, 5, 5, 5, 5, 2, 5, 5, 4, ...  \n",
       "13  [2, 1, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, ...  \n",
       "14  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "15  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "16  [5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "17  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "18  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "19  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "20  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "21  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "22  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "23  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "24  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "25  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "26  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification[\"Model Name\"] = df_classification.apply(lambda row: type(row[\"Model\"]).__name__, axis=1)\n",
    "df_classification.sort_values(by=\"F1-score score\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c344296-ea14-4402-8a5d-ab391127d016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f260cb22040>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFgCAYAAABuetoKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4u0lEQVR4nO3dd5ycVdn/8c83G1IgIUASNIQURHoiERYUUIoCggVUQJoIiqDPI6hYftYHATvYKSogD9hoFgzloYggSM0CIZVgCCGFAAnEhBAg7fr9cc4kk82WSbKzc+/s9/167Sv3nPuee66Znew159xnzqWIwMzMzIqhR60DMDMzszWcmM3MzArEidnMzKxAnJjNzMwKxInZzMysQHrWOoD1ddhhh8Wtt95a6zDMrHtSrQOw+lfVHrOkwyRNkzRd0ldb2D9c0l2SHpM0QdJ72zvnggULqhOsmZlZAVQtMUtqAC4GDgd2BY6XtGuzw74JXBcRbwWOAy6pVjxmZmZdQTV7zHsD0yNiRkQsA64Bjmx2TACb5+0BwLNVjMfMzKzwqnmNeSgwu+z2HOBtzY45B7hd0pnAZsDBVYzHzMys8Go9K/t44MqI2BZ4L/A7SevEJOl0SU2SmubPn9/pQZqZmXWWaibmucCwstvb5rZypwLXAUTEA0AfYFDzE0XEpRHRGBGNgwcPrlK4ZmZmtVfNxDwO2EHSdpJ6kSZ3jW12zCzg3QCSdiElZneJzcys26paYo6IFcAZwG3AVNLs68mSzpN0RD7si8Bpkh4HrgZOCZe7MjOzbkxdLQ82NjZGU1NTrcMws+7JC4xY1dV68peZmZmV6XJLcq6P5auWM+flOSxbuYyh/YbSr1e/WodkNfLK8leY+/JcGno0MLz/cDZp2KTWIVkNvLZ8OTMXPsf0xU+wbb9tGNx3G4YO2LLWYZmtpW4T86LXFjHr5VncNOMm5iyZw8d2/Rhb992a7bbYrtahWSeb/fJsLhh3AXfNvosGNXDSLidxyqhTGNh3YK1Ds060bMUqHn72cdRjJUP7bUOvhj48vfjfrFi5HSO28rc9rDjqNjHPXTKXG2fcyLSXpgFw56w7GT1wNNv024bePXvXODrrTDc9dRN3zb4LgJWxkiunXMnuW+/OwSO8nk13MmfxPJ5dOoMZi6ev/ruw01Y7cdLOH69xZGZrq9trzC8vf5lpL03j0Rce5dEXHmXaS9PYdJNNWbJ8Sa1Ds070yrJXuO2Z29Zpf/i5h2sQjdXS4mUvM2rw6HX+Lrz02sJah2a2lrpNzD217mDAotcX0W8TX2fuTnr37M2YwWPWad9lq106PxirqcF930BPeq3TvlXvrWsQjVnr6nYoe/Pem7PTVjutvr3TVjuxWa/N6NGjbj+LWAt69ujJCTufwL1z7uWFV18AYPfBu7PXG/eqcWTW2RoaVjF+3iPr/F1oaFhZw6jM1lW332Oet2Qef5v+N/bfdn8aejRw16y7OGDYAewy0D2l7mjB0gU8u+RZevboyTb9t2GL3lvUOiSrgZkLZ9NDYvlK0WeTnqyKlQwbsM36nMLfY7aqq9se85B+Qzhx1xPp36s/ANv022b1tnU/l068dK0JP19/29drHJHVwsgth7V/kFmN1W1iBtZKxE7K3Vtpwo+ZWdH5gquZmVmB1HWP2ayk+YQfM7OicmK2bsHXlM2sq/BQtpmZWYE4MZuZmRWIE7OZmVmBODGbmZkViBOzmZlZgTgxm5mZFYgTs5mZWYE4MZuZmRWIE7OZmVmBODGbmZkViBOzmZlZgTgxm5mZFYgTs5mZWYE4MZuZmRWIE7OZmVmBODGbmZkViBOzdQsvvvpii9tmZkXjxGx1b8L8CZx555k8vejptbbNzIqoZ60DMKumVbGKBa8uYPJLkzn99tNZsnwJwOp/zcyKxj1mq2s91IP9t92fs/Y4i+eWPseS5Uv40QE/YvSg0bUOzcysRU7MVvemvDiFSydcSs8ePemhHpz/8PkeyjazwqpqYpZ0mKRpkqZL+moL+38qaXz+eVLSf6oZj3U/paFsSVx52JX85ICfsOC1BR7KNrPCUkRU58RSA/AkcAgwBxgHHB8RU1o5/kzgrRHxibbO29jYGE1NTR0drtWxFatWMHfJXEZsPmKtbbMNoFoHYPWvmj3mvYHpETEjIpYB1wBHtnH88cDVVYzHuqmePXquTsTl22ZmRVTNxDwUmF12e05uW4ekEcB2wD9a2X+6pCZJTfPnz+/wQM3MzIqiKJO/jgP+FBErW9oZEZdGRGNENA4ePLiTQzMzM+s81UzMc4FhZbe3zW0tOQ4PY5uZmVU1MY8DdpC0naRepOQ7tvlBknYGtgQeqGIsZmZmXULVEnNErADOAG4DpgLXRcRkSedJOqLs0OOAa6Ja08PNzMy6kKp9Xapa/HUpM6shf13Kqq4ok7/MzMwMJ2YzM7NCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYra6t+Dl17lv+gJeeX3F6u2lr6+odVhmZi1yYra6tmpVcPPEeZx4+UP84aFZ/OSOaZx4+UNMmLuo1qGZmbWoZ60DMKumHj3Eu3fZmjumPM/3bpkKwCf2G8mOb+hX48jMzFrmHrPVvT49GxgyoM/q20O26Evvng01jMjMrHVOzFbXSkPZ1z8yh2P3Gsa+2w/kuzdPZaKHss2soDyUbXWtRw+x54gt+dJ7dmLS3EXsts0A9t9xMG/o37vWoZmZtciJ2eraqlXBnx6Zw13TXuCZF5cCMHLgpmzdvzfbDfZ1ZjMrHg9lW11bumwF/5q+YHVSBpj54lIen/Of2gVlZtYGJ2ara5v17snBu2y9TnvjiC1rEI2ZWfucmK2uSeIjjcPYY/gWq9uO3mMoe2+3Ve2CMjNrQ1WvMUs6DPg50ABcHhE/aOGYjwDnAAE8HhEnVDMm637eNLgfV31ib55b9Bo9e4ghW/ShzyaeXmFmxVS1v06SGoCLgUOAOcA4SWMjYkrZMTsAXwP2i4iFktYdczTrABfcNo2p8xYDsMuQzTnvyFE1jsjMrGXV7DbsDUyPiBkAkq4BjgSmlB1zGnBxRCwEiIgXqhiPdWNT5y1m3MyFtQ7DzKxd1bzGPBSYXXZ7Tm4rtyOwo6T7JD2Yh77XIel0SU2SmubPn1+lcM3MzGqv1hfaegI7AAcC2wL3SBodEf8pPygiLgUuBWhsbIxOjtHqwC5DNm9x28ysaKqZmOcCw8pub5vbys0BHoqI5cDTkp4kJepxVYzLuiFfUzazrqKaQ9njgB0kbSepF3AcMLbZMTeQestIGkQa2p5RxZjMzMwKrWqJOSJWAGcAtwFTgesiYrKk8yQdkQ+7DXhR0hTgLuDLEfFiR8XwzIuvsGzFqnW2zczMikoRXeuSbWNjYzQ1NbV73JRnF3PyFQ9z9gd2ZfvBm3HyFeM4+wO7ctioN7JJg9dVMbMNoloHYPWv1pO/qmbTXj0Y1K83n73mMXo19ECCQf16OymbmVmh1W2WGjmoH+d9cDci4PUVqzh1v+3Yc8QWtQ7LzMysTXWbmKc8u5hP/+4RevfswZABfbjkn09x2+TnWb7S15nNzKy46nooe/hWm/KVw3bmjQP6cNa14xnsoWwzMyu4up38BfDC4tfYevM+62ybmW0gT/6yqqvr7mN5InZSNjOzrqCuE7OZmVlX48RsZmZWIE7MZmZmBeLEbGZmViBOzGZmZgXixGxmZlYgdbvACMDZf5vE1HmLAdhlyOauyWtmZoVX14l56rzFjJu5sNZhmJmZVcxD2WZmZgVS1z3mXYZs3uK2mZlZUdV1YvY1ZTMz62o8lG1m1gkkrZQ0XtLjkh6VtG8F91nSGbFZsdR1j9nMrEBejYgxAJLeA3wfOKCmEbVAkkiVB128vkbcYzYz63ybAwsBJPWTdGfuRU+UdGTzg1s7RtJISVMlXSZpsqTbJfXN+94s6e9lPfTtc/uXJY2TNEHSuWXnmSbpt8AkYFgnvQ7WgrruMa9cFcx66RWWrQi23aovm/Wq66drZsXWV9J4oA8wBHhXbn8N+FBELJY0CHhQ0tiIiLL7tnhM3rcDcHxEnCbpOuAo4PfAH4AfRMRfJfUBekg6NB+/N6m29FhJ+wOzcvvJEfFg9V4Cq0TdZqpFS5fzh4ef4ed//zevr1jFu3femv95/66MHLRZrUMzs+6pfCh7H+C3kkaREuT3coJcBQwF3gA8V3bf1o4BeDoixuftR4CRkvoDQyPirwAR8Vp+3EOBQ4HH8vH9SAl5FvCMk3IxVJyYJW0aEUurGUxHemz2Qs6/ddrq23c+8QLbDdqMr793F3r0UA0jM7PuLiIeyD3fwcB78797RsRySTNJvepyJ7ZxzOtlx60E+rbx0AK+HxG/XqtRGgm8smHPxjpau9eYJe0raQrwRL69u6RLqh7ZRpow5z/rtN08cR4Lly7r/GDMzMpI2hloAF4EBgAv5IR7EDCihbtUcsxqEfEyMEfSB/Pj9Za0KXAb8AlJ/XL7UElbd9Tzso5RSY/5p8B7gLEAEfF4Hk4ptBED1x2yHrXNAPr1rtvRezMrttI1Zkg915MjYqWkPwA3SpoINJE7Qc1UckxzJwG/lnQesBw4JiJul7QL8ECafM0S4KOknrYVREVZKiJm519iSeF/iY0jtmTvkVvx8MyXANi8b0/OfPeb6b1JQ40jM7PuKCJa/OMTEQuAfVrZ16+9Y4BRZcf/qGz736yZYFZ+zp8DP2/rPFZblSTm2fmL8CFpE+BzwNTqhrXxhm65KZecuAdPPPcyry1fyZu37ueJX2ZmVniVJOZPkz5dDQXmArcDn6lmUB1lUP/evKN/71qHYWZmVrE2E7OkBuDnEXFiJ8VjZmbWrbU5KzsiVgIjJPXqpHjMzMy6tUqGsmcA9+VVZlZ/zy0iflK1qMzMzLqpShLzU/mnB9C/uuGYmZl1b+0m5ogoLXJemrbvMmRmZjUmaSUwkfR3/GngpIj4Twec9xSgMSLO6IBzDQAuBPYlfXf7PuDMiFi0sefubJLuBr4UEU3Vfqx2E3Ney/V3wFb59gLgYxExucqxmZnVhZFfvfkE4HvAcNK61F+f+YP3/XEjT1u+9vZVpG/LfHcjz9nRfgNMioiPAeRqVpcDx2zMSSX1jIgVHRBf1UhqyPO01lslZR8vBb4QESMiYgTwReCyCgM7LJcSmy7pqy3sP0XS/Fw8fLykT65f+GZmxZaT8mWkZTSV/70st3eUB0hfaUXS3pIekPSYpPsl7ZTbT5H0F0m3Svq3pPNLd5b0cUlPSnoY2K+sfaSkf+QSkXdKGp7br5T0S0kPSpoh6UBJV+QSlFfmY94M7Al8uyzO84BGSdtLukbS+8oe60pJR0tqkHRBWWnKT+X9B0q6N893miJpM0k357KWkyQdm487O993kqRLlVfHknS3pJ9Kaspx7pVfj39L+k7Z831C0h/yMX/KS5muRdKh+TV+VNL1ZUuczpT0Q0mPshEfPipJzJtFxF2lGxFxN9DuSh35q1YXA4cDuwLHS9q1hUOvjYgx+efyysI2M+syvgc0/+O+aW7faPlv7bvJyyaTlut8Z0S8FTi72eOMAY4FRgPHShomaQhwLikhv4P097rkQuCqiHgLaVnQX5Tt25K0GtlZ+bF/CuwGjJY0Jp9nfHmvMW+Pz8ddC3wkP4de+TncDJwKLIqIvYC9gNMkbZdPsQfwuYjYETgMeDYido+IUcCt+ZiLImKv3NYXeH9ZzMsiohH4FfA30ijDKOAUSQPzMTsBl0TELsBi4L+bvd6DgG8CB0fEHqQlUr9QdsiLEbFHRFzDBqokMc+Q9D/5k8RISd8kzdRuz97A9IiYERHLgGuAdQqAm5nVueHr2V6p0trbz5FKQN6R2wcA10uaxJpkWXJnRCzKZSCnkHrvbwPujoj5+W/1tWXH7wOUhtx/R0rcJTfmmtETgecjYmJErAImAyMriP//gIMk9SZ14O6JiFdJZSk/lp/bQ8BAUmlKgIcj4um8PRE4JPdQ31l23fogSQ8prSv+rmbPf2zZfSdHxLyIeJ2U04blfbMj4r68/ftmzxng7aQPHfflGE9m7aIi17KRKknMnyCVG/sL8GdgUG5rz1BgdtntObmtuaPycMWfJA1rYT+STs/DD03z58+v4KHNzApj1nq2V6p0jbk0RF5akfHbwF25x/gB1i4h2bxE5MZU9Smda1Wz867K550CjJG0Os/k7THAlPzh4G5SkaRjWZPQRJogVhpJ3S4ibs/7yr+y+ySpBz0R+E4ewu4DXAIcHRGjSZcQWnr+rcUMEM2eZ/PbAu4oi2/XiDi1bP9Gl89sNzFHxMKI+Gzumu8ZEZ+PiIUb+8DZjcDIPExyB3BVKzFcGhGNEdE4ePDgDnpoM7NO8XWgeS37pbl9o0XEUuCzwBcl9ST1mOfm3adUcIqHgAMkDVSqh1B+bfR+4Li8fSJw73rENR14jDTsW/JN4NG8D1Iy/jjwTtYMRd8G/FeOBUk7Slrn8qmkbYClEfF74AJSki4l4QX5uu/RlcZbZrikUsGQE4B/Ndv/ILBfvoZOvta94wY8Tqsqqcd8h6Qtym5vKem2Cs49lzVDAwDbsubNAkBEvJiHESDN1NuzgvOamXUZefb1acAzpN7XM8BpHTAre7WIeAyYABwPnA98X9JjVPaV2HnAOaQJZPexdpGiM4GPS5pAKiP5ufUM7VRgR0lPSXoK2DG3ldwOHAD8PQ+jQ8oFU4BH83D8r1t5HqOBh/Nw8reA7+Svi10GTCIl+HHrGS/ANOAzkqaSrqP/snxnRMwnfeC5Or8uDwA7b8DjtErpEkEbB0iP5UkEbba1cL+ewJOkC/pzSS/QCeVfs5I0JL8pkPQh4CsR8fa2ztvY2BhNTVX/GpmZWUvU/iHWVUkaCdyULwPUTCXXF1ZJGh4RswAkjWDdMfd1RMQKSWeQPrU0AFdExGSlot1NETEW+KykI4AVwEtUNuxiZmZWtyrpMR9G+i7zP0mfFt8JnB4RlQxndzj3mM2shtxjtqqr5PrDrZL2IE0RB/h8RCyoblhmZmbdUyWTv/YjTcu/CdgC+HoezjYzM7MOVsn3mH8JLJW0O2l1k6eA31Y1KjMzs26qksS8Iq/uciRwcURcjMs/mpmZVUUlifllSV8DPgrcnFdu2aS6YZmZWVskrVQq/jNJ0o3l601s5HlPkXRRB51rSbPb631u5eIWHRFPNSgV17ipI89ZSWI+lrR02akR8RxpoZALOjIIM7O6ds6AEzhnwEzOGbAq/9sRlaVezUtCjiJ93fQz7d2hO8hraBRWJfFVsiTncxHxk4i4N9+eFRG+xmxmVomUhNcp+9hBybmkcGUf25PP8Ysc44xSr1jJRUolg/8ObF12nz0l/VPSI5JuU6qMVSrp+DNJTcDnJB2TRxIel3RP2XO5V6lU46OS9s3tB+Zz/i3H8QNJJ0p6WNJESduXxfsrpboNT0p6fwvPabP8OjycX/8jy177sZL+AdzZ3mtT6E8WZmZ1oK2yjxu9LKfWlH38TW4qlX1cIeng/DhH5X1jgLeSRkGnSbqQtMDTuaQlkRcBd5HWuIY1ZR+vkvQJUtnHD+Z9pbKPR5CqNu0HfBIYJ2lMRIyvIPwhpOpNO+dz/An4EKn04q6kqllTgCuU1s6+EDgyIuYr1V/+LmuKKvXKJR1Rqiz1noiYWzbE/wJwSES8JmkH4GqgMe/bHdiFNPIwA7g8IvaW9DnSsqSfz8eNJFVO3B64S3m97DLfAP4REZ/Ij/tw/nABaS3vt0TES+29KE7MZmbVVe2yj0NJ61uXl328KiefYO05QXeWyiNKKpV9HEQu+5jbryWtaQ0p8X44b/+OtA53yY0RETkJPh8RE/P9S2Ufx7cSd/mqVjfkUpFTJL0ht+0PXJ1rNz+be5mQkvUo4A5JkFaUnFd2rvJyi/cBV0q6jlQZkfw6XKRUK3pl2XMEGFe2PPRTpDW8IVWuOqjsuOtyvP+WNIN118g+FDhC0pfy7T6s+T3fUUlShsq+x/wBlZXtMjOz9dJdyz4CvCqpV9m+rYDyBarK79feqmoi1VAulVscHRGHlu0vLwn5aVIlq2HAI5IGAmcBz5N6x41AeVzN4y9/buWvUSUlIY8qi3F4RJSKglRcDrLSyV//lnS+pA6toGFm1g10y7KP2T9J3+hBUl/gI6Sh8rbcAxwrqSFfQy71WKcBg5VLMkraRNJuLZ1A0vYR8VBEnA3MJyXoAcC83OM9idTjXl/HSOqRrzu/KcdU7jbgTOUuvaQ2iz21ppLJXx8lXZN4ijQ08ICk0yX5u8xmZu05Z1GLZR9ze4cocNnHzwEfzkPuDwLXR8Q97dznr8C/SdeWf5vjIpeFPBr4oaTHSUPl+7ZyjgvyxK1JpA8XjwOXACfn++7MevRgy8wCHgb+D/h0RLzWbP+3SUPmE/KQ/rc34DHaL2Kx+sA0FHAS6SL4VODNwC8i4sINeeAN5SIWZlZDLmLRTeXZ5jdFxJ+q/ViVXGM+QtJfgbtJnwT2jojDSeP0X6xueGZmZt1LJRf+jwJ+2nz4ISKWSjq1OmGZmZkVR0Sc0lmPVUliPoeyKen5Av4bImJmRLT7RWkzMzOrXCWzsq8nTRkvWZnbzMzMrINVkph75tlwwOqZcb3aON7MzMw2UCWJeb6kI0o38tqfC9o43szMzDZQJdeYPw38QalUl4DZwMeqGpWZmVk3VcmXz58C3i6pX769pJ27mJlZmdFXjT6BVExiOGmRiq9PPHlihy0wYvWlonVSJb0P2A3ok1caIyLOq2JcZmZ1ISfly1hTYWoEcNnoq0bj5GwtqWSBkV+R1ss+kzSUfQzpjWVmZu1rq+yj2Toqmfy1b0R8DFgYEeeSyoDt2M59zMwsqVbZR6tTlSTm0iLdSyVtAywnFbc2M7P2Vavso9WpShLzjZK2AC4AHgVmAr4uYmZWmaqWfbT602ZiltQDuDMi/hMRfyZdW94517g0M7N25Ale65R99MQva027ZR8lPRYRG1TsuRpc9tHMashlH63qKhnKvlPSUSp9T8rMzMyqppLE/ClS0YrXJS2W9LKkxVWOy8zMrFuqZOWv/p0RiJmZmVWQmCXt31J7RNzT8eGYmZl1b5Usyfnlsu0+wN7AI8C7qhKRmZlZN9buNeaI+EDZzyHAKGBhJSeXdJikaZKmS/pqG8cdJSkkNVYeupmZWf2pZPJXc3OAXdo7SFIDcDFwOLArcLykXVs4rj/wOeChDYjFzKzLkPQNSZMlTZA0XtLb1vP+IyVNqlZ8VgyVXGO+kPSleEiJfAxpBbD27A1Mj4gZ+TzXAEcCU5od923gh6w9ZG5mVlck7QO8H9gjIl6XNAjoVeXH7BkRK6r5GNbxKukxN5GuKT8CPAB8JSI+WsH9hgKzy27PyW2rSdoDGBYRN1cWrplZlzUEWBARrwNExIKIeFbSXpLul/S4pIcl9c8943slPZp/9m1+MkkNki6QNC73wD+V2w/M9x3Luh0h6wIqmfz1J+C1iFgJq98Mm0ZE87Vf10te7vMnwCkVHHs6cDrA8OEuyGJmXdLtwNmSngT+DlxL6uxcCxwbEeMkbQ68CrwAHBIRr0naAbgaaD4H51RgUUTsJak3cJ+k2/O+PYBREfF09Z+WdbSKVv4C+pbd7kt6U7VnLjCs7Pa2ua2kP2ki2d2SZgJvB8a2NAEsIi6NiMaIaBw8eHAFD21mViwRsQTYk9TJmE9KyJ8C5kXEuHzM4jz0vAlwmaSJpAWe1pmfAxwKfEzSeNIcnYHADnnfw07KXVclPeY++Q0FpDeXpOZFv1syDthB0nakhHwccELZeRYBg0q3Jd0NfCkivBC2mdWlPPJ4N6lDMhH4TCuHngU8D+xO6kC91sIxAs6MiNvWapQOBF7pmIitFirpMb+SrwUDIGlP0lBLm/KnvjOA24CpwHURMVnSeZKO2NCAzcy6Ikk75WHpkjGkv41DJO2Vj+kvqScwgNSTXgWcBDS0cMrbgP+StEm+746SNqvmc7DOUUmP+fPA9ZKeJX1CeyNwbCUnj4hbgFuatbVYMjIiDqzknGZmXVQ/4MJc334FMJ00rP2/ub0vqdNzMHAJ8GdJHwNupeUe8OXASODRXGRoPvDB6j4F6wztln0EyJ/Idso3p0XE8qpG1QaXfTSzGnKVPau6doeyJX0G2CwiJkXEJKCfpP+ufmhmZmbdTyXXmE+LiP+UbkTEQuC0qkVkZmbWjVWSmBvy9Qtg9VKbVV2txszMrLuqZPLXrcC1kn6db38qt5mZmVkHqyQxf4U0c/C/8u07gMuqFpGZmVk3VknZx1UR8auIODoijiatvXph9UMzMzPrfioq+yjprZLOz0tnngc8UdWozMysTbmG/e/LbveUNF/STfn2EZK+2s45RubzfKesbZCk5ZIu2sC4dpJ0dy5rOVXSpRt4nislHb0h9+3qWh3KlrQjcHz+WUBa11URcVAnxWZmVhcaGxtPAL4HDAdmAV9vamr640ae9hVglKS+EfEqcAhl9QgiYiwwtoLzPA28D/hmvn0MMHkj4voF8NOI+BuApNEbca6K1VOJy7Z6zE8A7wLeHxHviIgLgZWdE5aZWX3ISfkyYARpgZIRwGW5fWPdQkqqkDpRV5d2SDql1OvNvc9f5PKSM5r1RJcCU8sKCB0LXFd2ng9IekjSY5L+LukNuf3nks7O2++RdE+uGjiEVOYXgIiYmI9pkPQjSZNymcozc/vZuXTlJEmXln8LqCyGPSX9U9Ijkm6TNCS33y3pZ5KagM9tzAtZJG0l5g8D84C7JF0m6d141Rszs/X1PaB54Z9Nc/vGugY4TlIf4C2kKlOtGQK8A3g/8INWzjOM1AF7tmzfv4C3R8Rb83H/L7d/DThW0kGkXvLH89rePwX+Ien/JJ2VlyCFNIl4JDAmIt4C/CG3XxQRe0XEKFL1wveXB5ZXnrwQODoi9gSuAL5bdkivXH3wx2089y6l1aHsiLgBuCEvin4kac3srSX9EvhrRNze2n3NzGy11orIb3Rx+YiYIGkkqbd8SzuH35AT55RSr7fMrcC3SRWtrm22b1vSV2aHkNaweDo/9lJJpwH3AGdFxFO5/X8l3QYcRsodn5K0O2kN8F+Vhpsj4qV8/oMk/T/Sh5WtSMPoN5Y9/k6kEsF35M50A6nTWNI83i6vklnZr0TEHyPiA6Rf0GOkr1CZmVn7Zq1n+/oaC/yIsmHsVrxetr3W6GdELAMeAb4I/KnZ/S4k9WpHk9ax6FO2bzTwIrBNs/M9GxFXRMSRpIIdo1oKKPf0LyH1hkeThvz7ND8MmBwRY/LP6Ig4tGx/3ZW4rGhWdklELIyISyPi3dUKyMysznyddB233NLc3hGuAM4tXcvdCD8GvlLWky0ZwJpJZSeXGiWNICXytwKHS3pbbj+srBTlG4GB+f53kHrPPfO+rViThBdI6ge0NAt7GjBY0j75fptI2m0jn2uhrVdiNjOz9ZNnX58GPANE/ve0DpiVDUBEzImIX3TAeSZHxFUt7DqHVPr3EdI3dMgTtH4DfCkingVOBS7PPeBDgUmSHifVjP5yRDxHKlM5C5iQ952Q6zBcBkzKx45rIa5lpIT9w3y/8cC+G/t8i6yiso9F4rKPZlZDngBrVeces5mZWYE4MZuZmRWIE7OZmVmBODGbmZkViBOzmZlZgTgxm5mZFYgTs5lZFyXpG5Im56IQ4yW9TdLnJTVfm3tjHmOmpEEbcf/yYhouCVmBVtfKNjOzjdfY2NgL+Fu+eQxwfd4+sqmpadmGnjevhPV+YI+IeD0nz16ktaN/z7qrjXUKSQ0R0VolQpeErIB7zGZm1fU34ID8M6ds+29t3akCQ4AFEfE6QEQsIK2QtQ2pKuBdAJJ+Kakp96zPLd0594TPlfSopImSds7tAyXdno+/nLJFVSTdkEsvTpZ0eln7Ekk/zitz7SPp45KelPQwsF+zmF0Ssh1OzGZmnaMvad3pvh10vtuBYTkBXiLpgLw057PAQRFxUD7uGxHRSCoLeYCkt5SdY0FE7AH8EvhSbvsW8K+I2A34K2tXwfpELr3YCHxW0sDcvhnwUETsDjwFnEtKyO8Adi27v0tCVsCJ2cysuo4Bmg9Zl9Z/3mARsQTYk5TU5pNKM57SwqEfkfQoqTLgbqydKP+S/32ElBgB9icNhRMRNwMLy47/bO4VPwgMA3bI7SuBP+fttwF3R8T8vM716rKMEfG/wC6k4fwDgQcl9SaVhPx1KyUhH5I0EXhXjr9ceUnI8cA3SVUQS7pkSUhfYzYzq67rSdd+y/UilVc8fGNOnK/l3g3cnZPXyeX7JW1H6gnvFRELJV3J2mUVS6UgV9JOPpB0ICmB7pNrMd9ddq7X2riu3DzmZ0k92yskTaL9kpCNETFb0jm0XhJyn1YerkuWhHSP2cysc7wKLMr/brQ8w3mHsqYxpMpVLwP9c9vmpOS0SNIbqOyDwD3ACfkxDge2zO0DgIU5Ke8MvL2V+z9EGjIfmIeajymL2SUhK+Aes5lZdR1JK7OyN/K8/YAL83XaFcB00rD28cCtkp6NiIMkPQY8AcwG7qvgvOcCV0uaDNxPKtUIcCvwaUlTSQnxwZbuHBHzcu/2AeA/pDKNJYcCP5f0Wr795Yh4Lk8y25FUEnI5cFlEXCSpVBLyOVopCZm/NvULSQNIOe1nwOQKnmdhueyjmVnlXPbRqs5D2WZmZgXixGxmZlYgTsxmZmYFUtXEnGfgTZM0XdJXW9j/6bzizHhJ/5K0a0vnMTMz6y6qlpglNQAXk6bn7woc30Li/WNEjI6IMcD5wE+qFY+ZmVlXUM0e897A9IiYkVd/uYZmXw+IiMVlNzcDutYUcTMzsw5Wze8xDyV9b65kDmmptrVI+gzwBdJKOO9q6UR5sfTTAYYPH97SIWZmZnWh5pO/IuLiiNge+AppndOWjrk0L0TeOHjw4M4N0MzMrBNVs8c8l7TIecm2ua0115AqnJiZ1ZXGxsbFrFkmE+DlpqamzWsVjxVbNXvM44AdJG0nqRdwHDC2/IBm67y+D/h3FeMxM6uV/u3cNlutaj3miFgh6QzgNqABuCIiJks6D2iKiLHAGZIOBpaTSoud3PoZzczM6l9Vi1hExC3ALc3azi7b/lw1H9/MzKyrqfnkLzOzbuDldm6breayj2ZmVeaJXrY+3GM2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAqnvxPzSDFixbN1tMzOzgqrfxDxvIvzmEJg6FuZNWLO9cnmtIzMzM2tVz1oHUDW9NoP+28BfPgkNvUA9oP8boWGTWkdmZmbWqvrtMQ98Exz+Q4iAFa/D2/8btt271lGZmZm1qX4T87yJcO1HYZO+MGA4/OsnHso2M7PCq++h7K3eDAd/CzbfBv7yKeg/xEPZZmZWaIqIWsewXhobG6Opqamyg19+Afpvve62mdmGUa0DsPpXv0PZsHYidlI2M7MuoL4Ts5mZWRfjxGxmZlYg9Tv5C+Dl5+GFybD8NRi0EwzavtYRmZmZtal+E/PCWfCX02D2g+l2nwFw0g0wdI+ahmVmZtaWqg5lSzpM0jRJ0yV9tYX9X5A0RdIESXdKGtFhDz77oTVJGeC1RfDP81Pv2czMrKCq1mOW1ABcDBwCzAHGSRobEVPKDnsMaIyIpZL+CzgfOLZDAlg4c9225ybAsiWwSZ8OeQjrQm75Ejw3KW2/cRS890e1jcfMrBXVHMreG5geETMAJF0DHAmsTswRcVfZ8Q8CH+2wRx/61nXbRn0Y+m7VYQ9hXchzk2DWA7WOwsysXdUcyh4KzC67PSe3teZU4P9a2iHpdElNkprmz59f4aM3wiHfTktyAuxyBDR+Anp4IrqZmRVXISZ/Sfoo0Agc0NL+iLgUuBTSyl8VnbTvFrDPGbDz+2HlMthiOPTatIMiti7njaNa3jYzK5hqJua5wLCy29vmtrVIOhj4BnBARLzeoRH06JGqTJn5mrKZdRHVTMzjgB0kbUdKyMcBJ5QfIOmtwK+BwyLihQ6PwBN+zMysi6laYo6IFZLOAG4DGoArImKypPOApogYC1wA9AOulwQwKyKO6LAgPOHHzMy6mKpeY46IW4BbmrWdXbZ9cDUf38zMrKvxFGUzM7MCKcSs7KrxTFwzM+ti6jsxe7KXmZl1MR7Ktvr3+stpIuCqlWtvm5kVkBOz1bdVq2DyDXDp/jDtFnjkqrQ9+6FaR2Zm1qL6Hso269EDhu0NA0bAtXkp9h0OgQHD2r6fmVmNuMds9W/zoTD6qDW3dz8BNt+mdvFYbb30NMz4Jzw30WVgrZDcY7b6tmoVTP4r3HMBjHgHLJ4Lf/kk9H8jjNi31tFZZ5t5H1xzfKrPrh7wrv+BvU+H3v1qHZnZak7MVt9KQ9mNp8I7z4JlS+GhX3souzta8gLc8N8pKQPEKrjzXBj5jvQeMSsIJ2arf4N3gkO/s6a6WPm2dR9LX4T/zFy3ffE6tXXMasrXmK17KE/ETsrd02aDYOCb12336IkVjBOzmXUPmw2GD16S/gVo2AQO/yFsvWtt4zJrxkPZZtZ9DHsb/Nf9sOR56L15mrHf4D+DVix+R5pZ93LP+a7TboXmxGxm3YvrtFvB+RqzmZlZgbjHbGbdi8vBWsE5MZtZ9+JrylZwTszWPbwwFZ6fkr4iM+QtsOXIWkdkZtYiJ2arf3Megd9+AJa9km4PGA4n/QUG7VDbuMzMWuDJX1bfViyHBy5ak5QBFs2CGXfXLCQzs7Y4MVt9W/kazH9i3fYXn+r8WMzMKuDEbPWtd39460nrtm//rs6PxcysAk7MVv92+yDs9zno2Rv6bAHv+wkMe3uto7JaWbGs5W2zglBE1DqG9dLY2BhNTU21DsO6mlUrYdFc6NETBmxT62isVmaPg+cnwluOg+cnp+3Rx0LvzSo9g6oZnhl4VrZ1Fz0aYMvhtY7CamnpQrj/FzB1LLwwDR7/A6gHjNgv1ew2KwgnZjPrHjbdEg77PiycCQ//KrV98k4nZSscX2M2s+5j8TxY+PSa23Mfgddfaf14sxpwYjaz7qE0lK0ecMot8KZ3wV3fhcVzah2Z2Vo8lG1m3cOmW8J7vgevvgRDdocthqdtD2VbwTgxm1n3scWw9NN826xAPJRtZmZWIE7MZmZmBeLEbGZmViBVTcySDpM0TdJ0SV9tYf/+kh6VtELS0dWMxczMrCuoWmKW1ABcDBwO7AocL2nXZofNAk4B/litOMzMzLqSas7K3huYHhEzACRdAxwJTCkdEBEz875VVYzDzMysy6jmUPZQYHbZ7Tm5bb1JOl1Sk6Sm+fPnd0hwZmZmRdQlJn9FxKUR0RgRjYMHD651OGZmZlVTzcQ8Fyj/9v62uc3MzMxaUc3EPA7YQdJ2knoBxwFjq/h4ZmZmXZ4iononl94L/AxoAK6IiO9KOg9oioixkvYC/gpsCbwGPBcRu7VzzvnAM+sZyiBgwfrGb3XJ7wUr2ZD3woKIOKwawZiVVDUxF4WkpohorHUcVnt+L1iJ3wtWVF1i8peZmVl34cRsZmZWIN0lMV9a6wCsMPxesBK/F6yQusU1ZjMzs66iu/SYzczMugQnZjMzswKpi8Qs6RuSJkuaIGm8pG9J+n6zY8ZImpq3+0n6taSnJD0i6W5Jb6tN9F2XpCUdcI5GSb9oY/9ISSdUenw+Zqakifn98E9JIzY2zo4i6dOSPlbrONoiaWX+fzRJ0o2Stuig854i6aIOOlfpdzw+/+zbEedt4XHG5PUYytsOz2v3T5H0mKQf5/ZzJH2pAx/7/rLtC/LfuAu6wnvINk41q0t1Ckn7AO8H9oiI1yUNIpWZvBL4WtmhxwFX5+3LgaeBHSJilaTt8n2sk0VEE9DUxiEjgRPIpUErOL7koIhYIOlc4JvAaRsTpySR5mRsVCW0iPjVxty/k7waEWMAJF0FfAb4bk0jatlBEbFeC4RI6hkRK9bjLmOARuCWfP9RwEXA+yLiiVze9vT1iaFSEVH+YeN0YKuIWLm+59mA52w1Vg895iGk1XheB4iIBRFxD7CwWS/4I8DVkrYH3gZ8s/RHNiKejoibOzvwepR7GA/m3upfJW2Z2/cqG9G4QNKk3H6gpJvy9gFlPaDHJPUHfgC8M7ed1ez4fpL+t6x3fFQLIT1ArmomabCkP0sal3/2K2u/I/dILpf0jKRBubc+TdJvgUnAMElfzvedkJM+kjaTdLOkx3Mv89jc/oPcq5og6Ue5bXWvqo3X6m5JP5T0sKQnJb2zOr+tipS/fntLeiD/bu6XtFNuP0XSXyTdKunfks4v3VnSx/NzeBjYr6x9pKR/5Od+p6Thuf1KSb/Mr8uM/Pu+QtJUSVe2FWg75/yVpIeA8yVtn2N9RNK9knbOxx2Tf3+PS7pHaSnh84Bj8/vvWOD/Ad+NiCcAImJlRPyyhVhOy++Tx/N7btOWHiO37ZZ/1+Nz7Dvk9iX537FAP+ARScc2ew+19lzWes7r8fu2IoiILv1DesOOB54ELgEOyO1fAn6at99OWgYU4Ajgr7WOux5+gCUttE0o+x2cB/wsb08C9snbPwAm5e0DgZvy9o3AfmW/157l+1s4/oel8+fbW+Z/ZwKD8vbPgNPz9h+Bd+Tt4cDUvH0R8LW8fRgQpOUaRwKrgLfnfYeSvmIj0ofam4D9gaOAy8riGAAMBKax5psPW+R/zwG+1M5rdTfw47z9XuDvtfi9kpbSvR44LN/eHOiZtw8G/py3TwFm5Ofdh7Rk7jDSh+ZZwGCgF3AfcFHZ7/rkvP0J4Ia8fSVwTX6NjwQWA6Pz6/0IMKbsdzyR9H//oQrOeRPQkG/fSRotg/Qh/R95eyIwtNnv65RSzPn2o8Durbxu5b/bgWXt3wHObOMxLgROzNu9gL7N/3812y5/nNaey1rP2T9d66fLD2VHxBJJewLvBA4CrpX0VeBa4H5JX2TtYWyrEkkDSH9s/pmbrgKuV7pG2T8iHsjtfyRdfmjuPuAnkv4A/CUi5khq6yEPJv1uAYiIhWX77pK0FbAE+J+y43ctO+fmkvoB7wA+lM9xq6Ty8zwTEQ/m7UPzz2P5dj9gB+Be4MeSfkj60HCvpJ6k9d9/o9TDv6k88NZeq7JD/pL/fYT0AaEz9ZU0ntRTngrckdsHAFflHl0Am5Td586IWAQgaQowgvTh5u6ImJ/brwV2zMfvA3w4b/+OtXt1N0ZESJoIPB8RE/P9J5Nei/H5uOZD2W2d8/qIWJl/3/uS3pelfb3zv/cBV0q6jjWv/4YaJek7wBak98ltbTzGA8A3JG1Let//u5IHaOe5QH7OG/UsrCbqYSibSMNJd0fEt4AzgKMiYjbpOvIBpB7NtfnwycDuSteGrEAi4gfAJ4G+wH2lYbkNdBApOYwHzs1tPUi93zH5Z2hEtDeB7ZWybQHfL7v/myPiNxHxJLAHqTf0HUlnR7qmtzfwJ9KHkFvXM/7X878r6fy5IKVrzCNIz/kzuf3bwF0RMQr4AKl3XPJ62fbGxlw616pm5121Eect/R57AP8p+x2OiYhdACLi06T5CMNIw8YDWzjPZGDPCh7vSuCMiBhNev/1ae0xIuKPpJG8V4FbJL2rwufU6nNp9pyti+nyiVnSTqVrMtkY1lSfuhr4KTAjIuYARMRTpMlD5yp/zMzXpt7XeVHXp9xjWlh2TfQk4J8R8R/gZa255n9cS/eXtH1ETIyIH5LKhu4MvAz0b+Uh72BN0kD5Gm1ZPCuAzwMfy73n24Ezy44fkzfvI81BQNKhpGpnLbkN+ETuqSBpqKStJW0DLI2I3wMXAHvkYwZExC3AWcDuzWJr8bVq5XFrIiKWAp8FvphHAAawpqb6KRWc4iHgAEkDJW0CHFO2737WvA9OJI06bKx2zxkRi4GnJR0DaVKfpN3z9vYR8VBEnA3MJyXP5u+/C4CvS9ox36eHpE+3EEt/YF5+3ieWGlt6DElvIv2N+gXwN+AtlTzZtp6LdW1dPjGThomuUp5kQ5pdfU7edz2wG+sOY38SeAMwXWkS0pXAC50SbX3ZVNKcsp8vACcDF+TfxRjStVOAU4HL8hDpZsCiFs73+TwxZgKwHPg/0nXYlXmyzFnNjv8OsGVpMg2pl7yWiJhH+v1/hpRkGvMEmylA6Q/qucCh+b1wDPAc6Q9y83PdThqGfyAPs/6J9Ad4NPBwfm7fynH1B27Kz+VfwBdaeL6tvVaFERGPkX4Hx5OGhr8v6TEq6Lnm1/4c0lDtfaRh8ZIzgY/n534S8LkOCLfSc54InJrfM5NJ17Ih/S4m5vfB/cDjwF2kyx/jJR0bERNIH/auVvr65STgTS08xv+QPpjcBzxR1t7SY3wEmJTfP6OA367Hc27tuVgX5iU5rVNI6lcaNs5zAIZEREf8Md5oknoDKyNihdLX736Zh3LNzDpdl5/8ZV3G+yR9jfSee4bKhkI7y3DgOkk9gGVs5Heezcw2hnvMZmZmBVIP15jNzMzqhhOzmZlZgTgxm5mZFYgTs9WEpJD0+7LbPSXNz6tkrc95ZioVLlnvY3L7n8tuH6121mM2M6s2J2arlVdIyxb2zbcPYc3iFZ1pT0muLGZmheHEbLV0C1Bace14yhaCkbSVpBvyYiAPSnpLbh8o6XblSlCkJSNL9/mo1lTp+XWFy67+GPhG80a1XUnpBqVqVDMlnSHpC/m4B/MKY61W/TEza48Ts9XSNcBxkvqQliF8qGzfucBjEfEW4OusWQ3pW8C/ImI34K+k7yAjaRfgWFJ1qjGk9ZpPpH3XkZbQfHOz9ieAd0bEW4Gzge+V7RtFKpawF6lO8dJ83ANAqYD9paSKQnuSKp1dUkEsZmZeYMRqJyImSBpJ6i3f0mz3O0jFR4iIf+Se8uakMosfzu03a00lqHeTiguMU1oCvS+VLbO6krT+8ddIS4CWtFVJ6a6IeJm0/vciUrlBSEUs3qL2q/6YmbXKidlqbSzwI1Kd5Zaq+VRKwFUR8bUNuO/vSIl5UllbqZLSh/KHh7vL9jWveFReDaknZVV/NiAWM+vmPJRttXYFcG6p5m6Ze8lD0ZIOBBbkajr3ACfk9sNZUwnqTuBoSVvnfVtJGlFJABGxnFSFrLxIxvpWUio/n6v+mNkGc2K2moqIObncXXPnkGZMTwB+QKrEBOna8/6SJpOGtGfl80wh1bm9Pd/nDmDIeoTyG9YeQVqvSkotcNUfM9sgXivbzMysQNxjNjMzKxAnZjMzswJxYjYzMysQJ2YzM7MCcWI2MzMrECdmMzOzAnFiNjMzK5D/D1y2Mbtmc6ERAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 507.875x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(data=df_classification, x=\"Model Name\", y=\"Accuracy score\", style=\"Scaler\", hue=\"Balancer\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ecbc1d-668b-4b47-9987-004791b7b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path= os.path.join(base_path, classification_path, class_path, model_path, f\"{model_path}_classification_df.pkl\"), obj=df_classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDAC",
   "language": "python",
   "name": "pdac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
